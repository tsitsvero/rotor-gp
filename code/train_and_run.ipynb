{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python --RegexRemovePreprocessor.patterns=\"^%\"  train_and_run.ipynb\n",
    "\n",
    "# RULES:\n",
    "# 1. Do not make plot.show() only plot.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://docs.wandb.ai/guides/sweeps/walkthrough\n",
    "\n",
    "# import os\n",
    "# machine_name = os.uname()[1]\n",
    "\n",
    "# import wandb\n",
    "\n",
    "\n",
    "# wandb.init(project=\"rotor-gp\", save_code=True, notes=\"hello\", id=machine_name, mode='disabled')\n",
    "\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random',\n",
    "#     'metric': \n",
    "#     {\n",
    "#         'goal': 'minimize', \n",
    "#         'name': 'score'\n",
    "#         },\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         'x': {'max': 0.1, 'min': 0.01},\n",
    "#         'y': {'values': [1, 3, 7]},\n",
    "#      }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hydrogen: \n",
    "ind_H_1 = [117, 119, 123, 125, 135, 137, 116, 118, 122, 124, 134, 136] \n",
    "ind_H_2 = [115, 121, 127, 129, 133, 139, 132, 138, 126, 128, 114, 120] \n",
    "ind_H_3 = [130, 131, 140, 141, 142, 143, 144, 145, 164, 165, 166, 167, 192, 193, 206, 207, 250, 251] \n",
    "ind_H_4 = [146, 148, 150, 147, 149, 151, 152, 154, 156, 153, 155, 157, 158, 160, 162, 159, 161, 163, 168, 170, 172, 169, 171, 173, 174, 176, 178, 175, 177, 179, 180, 182, 184, 181, 183, 185, 186, 188, 190, 187, 189, 191, 194, 196, 198, 195, 197, 199, 200, 202, 204, 201, 203, 205, 208, 210, 212, 209, 211, 213, 214, 216, 218, 215, 217, 219, 220, 222, 224, 221, 223, 225, 226, 228, 230, 227, 229, 231, 232, 234, 236, 233, 235, 237, 238, 240, 242, 239, 241, 243, 244, 246, 248, 245, 247, 249, 252, 254, 256, 253, 255, 257, 258, 260, 262, 259, 261, 263] \n",
    "\n",
    "#Carbon: \n",
    "ind_C_1 = [6, 8, 10, 7, 9, 11] \n",
    "ind_C_2 = [18, 26, 44, 19, 27, 45] \n",
    "ind_C_3 = [24, 28, 16, 20, 42, 46, 17, 21, 25, 29, 43, 47] \n",
    "ind_C_4 = [30, 34, 14, 22, 40, 48, 15, 23, 31, 35, 41, 49] \n",
    "ind_C_5 = [12, 13, 32, 33, 38, 39] \n",
    "ind_C_6 = [36, 50, 64, 37, 51, 65, 52, 54, 80, 53, 55, 81, 62, 74, 96, 63, 75, 97] \n",
    "ind_C_7 = [56, 60, 57, 61, 68, 72, 69, 73, 66, 70, 67, 71, 78, 84, 79, 85, 58, 59, 88, 90, 89, 91, 86, 87, 92, 94, 93, 95, 76, 77, 82, 83, 98, 100, 99, 101] \n",
    "\n",
    "#Nytrogen: \n",
    "ind_N_1 = [102, 103, 104, 105, 106, 107] \n",
    "\n",
    "#Oxygen: \n",
    "ind_O_1 = [108, 109, 110, 111, 112, 113] \n",
    "\n",
    "#Silicon: \n",
    "ind_Si_1 = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "len(ind_C_1 + ind_C_2 + ind_C_3 + ind_C_4 + ind_C_5 + ind_C_6 + ind_C_7) + len(ind_H_1 + ind_H_2 + ind_H_3 + ind_H_4)+ len(ind_N_1)+ len(ind_O_1)+ len(ind_Si_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.21it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# # Construct the argument parser\n",
    "# ap = argparse.ArgumentParser()\n",
    "\n",
    "# # Add the arguments to the parser\n",
    "# ap.add_argument(\"-a\", \"--foperand\", required=True,\n",
    "#    help=\"first operand\")\n",
    "# ap.add_argument(\"-b\", \"--soperand\", required=True,\n",
    "#    help=\"second operand\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# print(args)\n",
    "\n",
    "# print(\"Starting script...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# export R=0; python ./train_and_run.py 2>&1 \n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../fande\") \n",
    "# sys.path.append(\"..\") \n",
    "import fande\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['VASP_PP_PATH'] = \"/home/qklmn/repos/pseudos\"\n",
    "\n",
    "def make_calc_dir():\n",
    "    if os.getcwd()[-4:] != 'code':\n",
    "        os.chdir('../../../code')\n",
    "    dir_name = f'{datetime.now().strftime(\"%Y-%m-%d_%H %M-%S_%f\")}'\n",
    "    dir_name = '../results/train_and_run/' + dir_name\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    abs_dir_path = os.path.abspath(dir_name)\n",
    "    return abs_dir_path\n",
    "\n",
    "temp_dir = make_calc_dir()\n",
    "os.chdir(temp_dir)\n",
    "print(\"Saving data to directory: \", temp_dir)\n",
    "\n",
    "\n",
    "import sys\n",
    "log_file = temp_dir + '/LOG_GPU.log'\n",
    "sys.stdout = open(log_file, 'w')\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "data_folder = \"/home/qklmn/data/\"\n",
    "# data_folder = \"/data1/simulations/\"\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "# traj_300 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_600 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1500 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1800 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_2100 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# print(len(traj_300), len(traj_600), len(traj_900), len(traj_1200), len(traj_1500), len(traj_1800), len(traj_2100))\n",
    "\n",
    "\n",
    "traj_300 = io.read(data_folder + \"datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_600 = io.read(data_folder + \"datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(data_folder + \"datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(data_folder + \"datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1500 = io.read(data_folder + \"datasets/rotors/different_temperatures/1500/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1800 = io.read(data_folder + \"datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_2100 = io.read(data_folder + \"datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "\n",
    "traj_train = traj_300[100:500:5].copy() #traj_1800.copy() + traj_2100.copy()\n",
    "# traj_train = traj_2100.copy()\n",
    "# training_indices = np.sort(  np.arange(0, 500, 5) )  \n",
    "# traj_train = [traj_md[i] for i in training_indices]\n",
    "\n",
    "traj_test = traj_300[400:420].copy()\n",
    "# test_indices = np.sort(  np.random.choice(np.arange(0,92795), 200, replace=False) ) \n",
    "# test_indices = np.sort(  np.arange(400,410,1) ) \n",
    "# traj_test = [traj_md[i] for i in test_indices]\n",
    "\n",
    "\n",
    "\n",
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "## Train data:\n",
    "energies_train = np.zeros(len(traj_train) )\n",
    "forces_train = np.zeros( (len(traj_train), len(traj_train[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_train):\n",
    "    energies_train[i] = snap.get_potential_energy()\n",
    "    forces_train[i] = snap.get_forces()\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train, 'forces': forces_train}\n",
    "## Test data:\n",
    "energies_test = np.zeros(len(traj_test) )\n",
    "forces_test = np.zeros( (len(traj_test), len(traj_test[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_test):\n",
    "    energies_test[i] = snap.get_potential_energy()\n",
    "    forces_test[i] = snap.get_forces()\n",
    "test_data = {'trajectory': traj_test, 'energies': energies_test, 'forces': forces_test}\n",
    "\n",
    "\n",
    "atomic_groups = [ind_H_1, ind_H_2, ind_H_3, ind_H_4, ind_C_1, ind_C_2, ind_C_3, ind_C_4, ind_C_5, ind_C_6, ind_C_7, ind_N_1, ind_O_1, ind_Si_1] \n",
    "\n",
    "train_centers_positions = sum(atomic_groups, []) #list(range(len(atoms)))\n",
    "train_derivatives_positions = sum(atomic_groups, [])#list(range(len(atoms)))\n",
    "\n",
    "# Hyperparameters:\n",
    "hparams = {}\n",
    "\n",
    "# Descriptors parameters:\n",
    "# https://github.com/lab-cosmo/librascal/blob/master/examples/MLIP_example.ipynb\n",
    "soap_params = {\n",
    "    # 'species': [\"H\", \"C\", \"O\", \"N\", \"Si\"],\n",
    "    # 'periodic': True,\n",
    "    'interaction_cutoff': 3.5,\n",
    "    'gaussian_sigma_constant': 0.1,\n",
    "    'max_radial': 4,\n",
    "    'max_angular': 4,\n",
    "    'cutoff_smooth_width': 0.1,\n",
    "    # 'average': \"off\",\n",
    "    # 'crossover': True,\n",
    "    # 'dtype': \"float64\",\n",
    "    # 'n_jobs': 10,\n",
    "    # 'sparse': False,\n",
    "    # 'positions': [7, 11, 15] # ignored\n",
    "}\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, test_data, hparams)\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"train\")\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"test\")\n",
    "\n",
    "\n",
    "\n",
    "for g in range(len(atomic_groups)):\n",
    "    print(\"\\n-----------\")\n",
    "    print(\"Group \", g)\n",
    "    print(\"-----------\")\n",
    "    plt.plot(fdm.train_F[g].cpu()[1::1], linestyle = 'None', marker='o', label='train')\n",
    "    plt.plot(fdm.test_F[g].cpu()[1::1], linestyle = 'None', marker='x', label='test')\n",
    "    plt.savefig(\"tran_test_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.hist(fdm.test_F[g].cpu().numpy())\n",
    "    plt.savefig(\"histogram_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "    print(f\"Number of training points for group {g}: \", fdm.train_DX[g].shape[-2])\n",
    "    print(f\"Number of test points for group {g}: \", fdm.test_DX[g].shape[-2])\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# total_training_random_samples = 10\n",
    "# high_force_samples = 5\n",
    "# random_samples = total_training_random_samples - high_force_samples\n",
    "\n",
    "# indices_high_force = torch.concat( \n",
    "#     (torch.topk(fdm.test_F[0], high_force_samples//2, largest=True)[1],  \n",
    "#      torch.topk(fdm.test_F[0], high_force_samples//2, largest=False)[1]) ).cpu().numpy()\n",
    "\n",
    "# ind_slice = np.sort(  \n",
    "#     np.random.choice(np.setdiff1d(np.arange(0, fdm.train_F[0].shape[0]), indices_high_force), random_samples, replace=False) )\n",
    "\n",
    "# indices = np.concatenate((ind_slice, indices_high_force))\n",
    "# indices = np.unique(indices)\n",
    "# print(\"High force indices: \", indices_high_force)\n",
    "# print(ind_slice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# seed_everything(42, workers=True)\n",
    "import torch\n",
    "\n",
    "hparams = {\n",
    "    'dtype' : 'float32',\n",
    "    'device' : 'gpu'\n",
    "}\n",
    "\n",
    "\n",
    "per_model_hparams = []\n",
    "\n",
    "train_DX = fdm.train_DX\n",
    "train_F = fdm.train_F\n",
    "test_DX = fdm.test_DX\n",
    "test_F = fdm.test_F\n",
    "\n",
    "\n",
    "\n",
    "### Prepare data loaders and specify how to sample data for each group:\n",
    "total_samples_per_group = [\n",
    "    1_000, # ind_H_1\n",
    "    1_000, # ind_H_2\n",
    "    1_000, # ind_H_3\n",
    "    1_000, # ind_H_4    \n",
    "    1_000, # ind_C_1\n",
    "    1_000, # ind_C_2\n",
    "    1_000, # ind_C_3\n",
    "    1_000, # ind_C_4\n",
    "    1_000, # ind_C_5\n",
    "    4_000, # ind_C_6\n",
    "    4_000, # ind_C_7\n",
    "    1_000, # ind_N_1\n",
    "    1_000, # ind_O_1\n",
    "    1_000, # ind_Si_1 \n",
    "    ]\n",
    "\n",
    "high_force_samples_per_group = [\n",
    "    0, # ind_H_1\n",
    "    0, # ind_H_2\n",
    "    0, # ind_H_3\n",
    "    0, # ind_H_4    \n",
    "    0, # ind_C_1\n",
    "    0, # ind_C_2\n",
    "    0, # ind_C_3\n",
    "    0, # ind_C_4\n",
    "    0, # ind_C_5\n",
    "    0, # ind_C_6\n",
    "    0, # ind_C_7\n",
    "    0, # ind_N_1\n",
    "    0, # ind_O_1\n",
    "    0, # ind_Si_1\n",
    "    ]\n",
    "\n",
    "train_data_loaders = fdm.prepare_train_data_loaders(\n",
    "    total_samples_per_group=total_samples_per_group,\n",
    "    high_force_samples_per_group=high_force_samples_per_group)\n",
    "\n",
    "hparams['train_indices'] = fdm.train_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdm.train_indices[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 523498.5 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 21085.8515625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 565.0213012695312 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 679467392.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 5553698304.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 282469152.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 357569600.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 485340160.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 19945696.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 14384915.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 28477778.0 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 188358.671875 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 51373.36328125 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 239282.390625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 1099348.75 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:337: NumericalWarning:\n",
      "\n",
      "CG terminated in 1000 iterations with average residual norm 9768.6416015625 which is larger than the tolerance of 1 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100\n",
    "lr = 0.05\n",
    "\n",
    "model_H_1_hparams = {\n",
    "    'atomic_group' : ind_H_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[0].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_2_hparams = {\n",
    "    'atomic_group' : ind_H_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_3_hparams = {\n",
    "    'atomic_group' : ind_H_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[2].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_4_hparams = {\n",
    "    'atomic_group' : ind_H_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[3].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_H = [model_H_1_hparams, model_H_2_hparams, model_H_3_hparams, model_H_4_hparams]\n",
    "\n",
    "model_C_1_hparams = {\n",
    "    'atomic_group' : ind_C_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[4].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_2_hparams = {\n",
    "    'atomic_group' : ind_C_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[5].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_3_hparams = {\n",
    "    'atomic_group' : ind_C_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[6].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_4_hparams = {\n",
    "    'atomic_group' : ind_C_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[7].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_5_hparams = {\n",
    "    'atomic_group' : ind_C_5,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[8].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_6_hparams = {\n",
    "    'atomic_group' : ind_C_6,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[9].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_7_hparams = {\n",
    "    'atomic_group' : ind_C_7,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[10].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "\n",
    "hparams_models_C =  [model_C_1_hparams, model_C_2_hparams, model_C_3_hparams, model_C_4_hparams, model_C_5_hparams,  model_C_6_hparams,  model_C_7_hparams]\n",
    "\n",
    "model_N_1_hparams = {\n",
    "    'atomic_group' : ind_N_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[11].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_N =  [model_N_1_hparams]\n",
    "\n",
    "model_O_1_hparams = {\n",
    "    'atomic_group' : ind_O_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[12].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_O =  [model_O_1_hparams]\n",
    "\n",
    "\n",
    "model_Si_1_hparams = {\n",
    "    'atomic_group' : ind_Si_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[13].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_Si =  [model_Si_1_hparams]\n",
    "\n",
    "# model_Si_hparams = {\n",
    "#     'atomic_group' : Si_atoms,\n",
    "#     'dtype' : hparams['dtype'],\n",
    "#     'device' : hparams['device'],\n",
    "#     'num_epochs' : 1, \n",
    "#     'learning_rate' : 0.01,\n",
    "#     'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "#     'soap_params' : soap_params,\n",
    "# }\n",
    "\n",
    "\n",
    "hparams['per_model_hparams'] = [ \n",
    "    model_H_1_hparams,\n",
    "    model_H_2_hparams,\n",
    "    model_H_3_hparams,\n",
    "    model_H_4_hparams, \n",
    "    model_C_1_hparams,\n",
    "    model_C_2_hparams,\n",
    "    model_C_3_hparams,\n",
    "    model_C_4_hparams,\n",
    "    model_C_5_hparams,\n",
    "    model_C_6_hparams,\n",
    "    model_C_7_hparams,\n",
    "    model_N_1_hparams,\n",
    "    model_O_1_hparams,\n",
    "    model_Si_1_hparams\n",
    "    ] # access per_model_hparams by model.model_id\n",
    "\n",
    "hparams['soap_dim'] = fdm.train_DX[0].shape[-1]\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "from fande.models import ModelForces, GroupModelForces, ModelEnergies, MyCallbacks\n",
    "\n",
    "model_H_1 = ModelForces(\n",
    "    train_x = train_data_loaders[0].dataset[:][0],\n",
    "    train_y = train_data_loaders[0].dataset[:][1],\n",
    "    atomic_group = ind_H_1,\n",
    "    hparams = hparams,\n",
    "    id=0)\n",
    "\n",
    "model_H_2 = ModelForces(\n",
    "    train_x = train_data_loaders[1].dataset[:][0],\n",
    "    train_y = train_data_loaders[1].dataset[:][1],\n",
    "    atomic_group = ind_H_2,\n",
    "    hparams = hparams,\n",
    "    id=1)\n",
    "\n",
    "model_H_3 = ModelForces(\n",
    "    train_x = train_data_loaders[2].dataset[:][0],\n",
    "    train_y = train_data_loaders[2].dataset[:][1],\n",
    "    atomic_group = ind_H_3,\n",
    "    hparams = hparams,\n",
    "    id=2)\n",
    "\n",
    "model_H_4 = ModelForces(\n",
    "    train_x = train_data_loaders[3].dataset[:][0],\n",
    "    train_y = train_data_loaders[3].dataset[:][1],\n",
    "    atomic_group = ind_H_4,\n",
    "    hparams = hparams,\n",
    "    id=3)\n",
    "\n",
    "\n",
    "\n",
    "model_C_1 = ModelForces(\n",
    "    train_x = train_data_loaders[4].dataset[:][0],\n",
    "    train_y = train_data_loaders[4].dataset[:][1],\n",
    "    atomic_group = ind_C_1,\n",
    "    hparams = hparams,\n",
    "    id=4)\n",
    "\n",
    "model_C_2 = ModelForces(\n",
    "    train_x = train_data_loaders[5].dataset[:][0],\n",
    "    train_y = train_data_loaders[5].dataset[:][1],\n",
    "    atomic_group = ind_C_2,\n",
    "    hparams = hparams,\n",
    "    id=5)\n",
    "\n",
    "model_C_3 = ModelForces(\n",
    "    train_x = train_data_loaders[6].dataset[:][0],\n",
    "    train_y = train_data_loaders[6].dataset[:][1],\n",
    "    atomic_group = ind_C_3,\n",
    "    hparams = hparams,\n",
    "    id=6)\n",
    "\n",
    "model_C_4 = ModelForces(\n",
    "    train_x = train_data_loaders[7].dataset[:][0],\n",
    "    train_y = train_data_loaders[7].dataset[:][1],\n",
    "    atomic_group = ind_C_4,\n",
    "    hparams = hparams,\n",
    "    id=7)\n",
    "\n",
    "model_C_5 = ModelForces(\n",
    "    train_x = train_data_loaders[8].dataset[:][0],\n",
    "    train_y = train_data_loaders[8].dataset[:][1],\n",
    "    atomic_group = ind_C_5,\n",
    "    hparams = hparams,\n",
    "    id=8)\n",
    "\n",
    "model_C_6 = ModelForces(\n",
    "    train_x = train_data_loaders[9].dataset[:][0],\n",
    "    train_y = train_data_loaders[9].dataset[:][1],\n",
    "    atomic_group = ind_C_6,\n",
    "    hparams = hparams,\n",
    "    id=9)\n",
    "\n",
    "model_C_7 = ModelForces(\n",
    "    train_x = train_data_loaders[10].dataset[:][0],\n",
    "    train_y = train_data_loaders[10].dataset[:][1],\n",
    "    atomic_group = ind_C_7,\n",
    "    hparams = hparams,\n",
    "    id=10)\n",
    "\n",
    "\n",
    "\n",
    "model_N_1 = ModelForces(\n",
    "    train_x = train_data_loaders[11].dataset[:][0],\n",
    "    train_y = train_data_loaders[11].dataset[:][1],\n",
    "    atomic_group = ind_N_1,\n",
    "    hparams = hparams,\n",
    "    id=11)\n",
    "\n",
    "\n",
    "model_O_1 = ModelForces(\n",
    "    train_x = train_data_loaders[12].dataset[:][0],\n",
    "    train_y = train_data_loaders[12].dataset[:][1],\n",
    "    atomic_group = ind_O_1,\n",
    "    hparams = hparams,\n",
    "    id=12)\n",
    "\n",
    "model_Si_1 = ModelForces(\n",
    "    train_x = train_data_loaders[13].dataset[:][0],\n",
    "    train_y = train_data_loaders[13].dataset[:][1],\n",
    "    atomic_group = ind_Si_1,\n",
    "    hparams = hparams,\n",
    "    id=13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AG_force_model = GroupModelForces(\n",
    "    models= [\n",
    "        model_H_1, \n",
    "        model_H_2, \n",
    "        model_H_3, \n",
    "        model_H_4, \n",
    "        model_C_1, \n",
    "        model_C_2, \n",
    "        model_C_3, \n",
    "        model_C_4, \n",
    "        model_C_5,\n",
    "        model_C_6, \n",
    "        model_C_7, \n",
    "        model_N_1,\n",
    "        model_O_1, \n",
    "        model_Si_1,\n",
    "        ], # model_N, model_O, model_Si],\n",
    "    train_data_loaders = train_data_loaders,\n",
    "    hparams=hparams)\n",
    "\n",
    "AG_force_model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052689068,\n",
       " 0.049605276,\n",
       " 0.07771337,\n",
       " 0.09678615,\n",
       " 0.08617227,\n",
       " 0.06964232,\n",
       " 0.074910276,\n",
       " 0.0783577,\n",
       " 0.05575946,\n",
       " 0.10518102,\n",
       " 0.14148727,\n",
       " 0.06739564,\n",
       " 0.058104258,\n",
       " 0.085866086]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING PREDICITONS ###\n",
    "print('Testing performance with (meta-)dynamics run...')\n",
    "\n",
    "from fande.predict import PredictorASE\n",
    "\n",
    "model_e = None\n",
    "trainer_e = None\n",
    "\n",
    "AG_force_model.eval()\n",
    "\n",
    "predictor = PredictorASE(\n",
    "            fdm,\n",
    "            model_e,\n",
    "            trainer_e,\n",
    "            AG_force_model,\n",
    "            # trainer_f,\n",
    "            hparams,\n",
    "            soap_params\n",
    ")\n",
    "\n",
    "rmse_per_model, mae_per_model = predictor.test_errors(view_worst_atoms=True)\n",
    "\n",
    "rmse_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exactly one of the parameters 'temperature', and 'temperature_K', must be given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[359], line 82\u001b[0m\n\u001b[1;32m     43\u001b[0m os\u001b[39m.\u001b[39mmakedirs(\u001b[39m\"\u001b[39m\u001b[39mmd_run/\u001b[39m\u001b[39m\"\u001b[39m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Verlet dynamics:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m# dyn = VelocityVerlet(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m# https://databases.fysik.dtu.dk/ase/tutorials/md/md.html\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m dyn \u001b[39m=\u001b[39m Langevin(atoms, \u001b[39m0.5\u001b[39;49m\u001b[39m*\u001b[39;49mfs, \n\u001b[1;32m     83\u001b[0m         \u001b[39m#        temperature_K=0.1/units.kB, \u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m                friction\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,\n\u001b[1;32m     85\u001b[0m         \u001b[39m#        fixcm=True, \u001b[39;49;00m\n\u001b[1;32m     86\u001b[0m                trajectory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmd_run/md_test.traj\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     87\u001b[0m                logfile\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmd_run/md_log.log\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     89\u001b[0m dyn\u001b[39m.\u001b[39mrun(\u001b[39m5_000\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m# # Structure optimization:\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# dyn = BFGS(\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m#     atoms,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m#     trajectory=\"../results/test/md_runs/md_test.traj\",\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m#     logfile=\"../results/test/md_runs/md_log.log\",)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m# dyn.run(fmax=0.1)\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/langevin.py:80\u001b[0m, in \u001b[0;36mLangevin.__init__\u001b[0;34m(self, atoms, timestep, temperature, friction, fixcm, temperature_K, trajectory, logfile, loginterval, communicator, rng, append_trajectory)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMissing \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfriction\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfr \u001b[39m=\u001b[39m friction\n\u001b[0;32m---> 80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp \u001b[39m=\u001b[39m units\u001b[39m.\u001b[39mkB \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_temperature(temperature,\n\u001b[1;32m     81\u001b[0m                                                  temperature_K, \u001b[39m'\u001b[39;49m\u001b[39meV\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfix_com \u001b[39m=\u001b[39m fixcm\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m communicator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/md.py:41\u001b[0m, in \u001b[0;36mprocess_temperature\u001b[0;34m(temperature, temperature_K, orig_unit)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Handle that temperature can be specified in multiple units.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39mFor at least a transition period, molecular dynamics in ASE can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mReturn value: Temperature in Kelvin.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m (temperature \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m+\u001b[39m (temperature_K \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExactly one of the parameters \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m                     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtemperature_K\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, must be given\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m temperature \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     w \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSpecify the temperature in K using the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtemperature_K\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exactly one of the parameters 'temperature', and 'temperature_K', must be given"
     ]
    }
   ],
   "source": [
    "### MD with fande calc\n",
    "from fande.ase import FandeCalc\n",
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal\n",
    "\n",
    "\n",
    "# from ase.geometry.analysis import Analysis\n",
    "from ase.constraints import FixAtoms, FixBondLengths\n",
    "from ase.optimize import BFGS\n",
    "from ase import units\n",
    "from ase.io import read\n",
    "import logging\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "from ase.md.nptberendsen import NPTBerendsen\n",
    "from ase.md.nvtberendsen import NVTBerendsen\n",
    "\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR) # logging.ERROR to disable or INFO\n",
    "\n",
    "# traj_md = read('../results/test/machine_learning/dftb_opt_1000_six_rings.traj', index=\":\")\n",
    "# traj_opt = read('../results/test/machine_learning/opt.traj', index=\":\")\n",
    "\n",
    "# atoms = fdm.mol_traj[10].copy()\n",
    "# atoms = traj_md[300].copy()\n",
    "# atoms = traj_opt[-1].copy()\n",
    "atoms = traj_test[10].copy()\n",
    "atoms.set_pbc(True)\n",
    "\n",
    "\n",
    "moving_atoms = sum(atomic_groups, []) \n",
    "fixed_atoms = list( set(range(264)) - set(moving_atoms) )\n",
    "fix_atoms = FixAtoms(indices=fixed_atoms)\n",
    "atoms.set_constraint(fix_atoms)\n",
    "\n",
    "\n",
    "atoms.calc = FandeCalc(predictor)\n",
    "# atoms.calc.set_atomic_groups([rings_carbons, rings_hydrogens], titles=[\"Rings carbons\", \"Rings hydrogens\"])\n",
    "# atoms.calc.set_forces_errors_plot_file(\"../results/test/md_runs/forces_errors.png\", loginterval=1)\n",
    "# atoms.calc = LennardJones()\n",
    "\n",
    "os.makedirs(\"md_run/\", exist_ok=True)\n",
    "\n",
    "# Verlet dynamics:\n",
    "# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
    "# dyn = VelocityVerlet(\n",
    "#     atoms,\n",
    "#     dt = 0.5*units.fs,\n",
    "#     trajectory=\"md_run/md_test.traj\",\n",
    "#     logfile=\"md_run/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPT(\n",
    "#     atoms,\n",
    "#     # dt = 0.5*units.fs,\n",
    "#     timestep=0.1,\n",
    "#     temperature_K=300,\n",
    "#     externalstress=0.0,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPTBerendsen(atoms, timestep=0.1 * units.fs, temperature_K=300,\n",
    "#                    taut=100 * units.fs, pressure_au=1.01325 * units.bar,\n",
    "#                    taup=1000 * units.fs, compressibility=4.57e-5 / units.bar,\n",
    "#                    trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#                    logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# dyn = NVTBerendsen(atoms, 0.5 * units.fs, 300, taut=0.5*1000*units.fs, \n",
    "#                    trajectory=\"md_run/md_test.traj\",   \n",
    "#                    logfile=\"md_run/md_log.log\")\n",
    "\n",
    "# dyn.run(100)\n",
    "\n",
    "# Langevin dynamics:\n",
    "# https://databases.fysik.dtu.dk/ase/tutorials/md/md.html\n",
    "# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
    "dyn = Langevin(atoms, 0.5*fs, \n",
    "               temperature_K=300, #0.1/units.kB, \n",
    "               friction=0.01,\n",
    "        #        fixcm=True, \n",
    "               trajectory='md_run/md_test.traj',\n",
    "               logfile=\"md_run/md_log.log\")\n",
    "\n",
    "dyn.run(5_000)\n",
    "\n",
    "# # Structure optimization:\n",
    "# dyn = BFGS(\n",
    "#     atoms,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "# dyn.run(fmax=0.1)\n",
    "\n",
    "\n",
    "print(\" ALL JOBS WITHIN PYTHON SCRIPT ARE DONE! \")\n",
    "\n",
    "print(\"TIMING: \", time.time()-start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
