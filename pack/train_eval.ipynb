{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dCOI-tn1woN"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsitsvero/rotor-gp/blob/main/pack/train_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGkUAB7q1woR"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znyGV5dF1woR",
        "outputId": "3b4615b4-d9a8-4955-8a93-4c59ab0b3845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lab-cosmo/librascal\n",
            "  Cloning https://github.com/lab-cosmo/librascal to /tmp/pip-req-build-eo9ugbmz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lab-cosmo/librascal /tmp/pip-req-build-eo9ugbmz\n",
            "  Resolved https://github.com/lab-cosmo/librascal to commit 6c55e99720f9a181f1efc5c7cd4976c87809d79b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/chem-gp/fande\n",
            "  Cloning https://github.com/chem-gp/fande to /tmp/pip-req-build-b23zn9dh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/chem-gp/fande /tmp/pip-req-build-b23zn9dh\n",
            "  Resolved https://github.com/chem-gp/fande to commit 353b1733424bfdd15a117ac41dd5f909ed5ce40c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.1.3-py3-none-any.whl (777 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xtb\n",
            "  Downloading xtb-22.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbstripout\n",
            "  Downloading nbstripout-0.6.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from rascal==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from rascal==0.0.0) (1.11.4)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from rascal==0.0.0) (3.7.1)\n",
            "Collecting ase>=3.19.0 (from rascal==0.0.0)\n",
            "  Downloading ase-3.22.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch)\n",
            "  Downloading linear_operator-0.5.2-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from xtb) (1.16.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from nbstripout) (5.9.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading jaxtyping-0.2.25-py3-none-any.whl (39 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->rascal==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->xtb) (2.21)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->nbstripout) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->nbstripout) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->nbstripout) (5.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->nbstripout) (4.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n",
            "Building wheels for collected packages: rascal, fande\n",
            "  Building wheel for rascal (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rascal: filename=rascal-0.0.0-cp310-cp310-linux_x86_64.whl size=1160758 sha256=7e54af908c1156a4f1c65e9cf3517b21348c362608f2cf19b1fdeb5db6edc81f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mdhvd21w/wheels/bc/72/69/ef99799b87ca514fefd4d408f33fd8e56427852b1cff5fe55a\n",
            "  Building wheel for fande (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fande: filename=fande-0.0.0-py3-none-any.whl size=54697 sha256=afbfd536d1eaa4824630d44a665f43d59aa4232452c9cc90630bb2c8f76bdf13\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mdhvd21w/wheels/30/ba/84/411722251f2aee25486664e17c8b197bbc34350633c9288672\n",
            "Successfully built rascal fande\n",
            "Installing collected packages: typeguard, smmap, setproctitle, sentry-sdk, lightning-utilities, fande, docker-pycreds, xtb, jaxtyping, gitdb, torchmetrics, linear-operator, GitPython, ase, wandb, rascal, pytorch-lightning, gpytorch, nbstripout\n",
            "Successfully installed GitPython-3.1.40 ase-3.22.1 docker-pycreds-0.4.0 fande-0.0.0 gitdb-4.0.11 gpytorch-1.11 jaxtyping-0.2.25 lightning-utilities-0.10.0 linear-operator-0.5.2 nbstripout-0.6.1 pytorch-lightning-2.1.3 rascal-0.0.0 sentry-sdk-1.39.1 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.2.1 typeguard-2.13.3 wandb-0.16.1 xtb-22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/lab-cosmo/librascal gpytorch pytorch-lightning wandb git+https://github.com/chem-gp/fande xtb nbstripout\n",
        "! nbstripout --install --global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Davwyq8M136x",
        "outputId": "8752ba29-054f-468b-8a53-c91fb7d9c8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tsitsvero/rotor-gp/main/pack/cook_model.py"
      ],
      "metadata": {
        "id": "XohhSji5O2WP",
        "outputId": "5d49bb38-8096-4f05-c862-3ee081b396b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-31 14:21:11--  https://raw.githubusercontent.com/tsitsvero/rotor-gp/main/pack/cook_model.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9070 (8.9K) [text/plain]\n",
            "Saving to: ‘cook_model.py’\n",
            "\n",
            "\rcook_model.py         0%[                    ]       0  --.-KB/s               \rcook_model.py       100%[===================>]   8.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-31 14:21:11 (80.2 MB/s) - ‘cook_model.py’ saved [9070/9070]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1vtf8fz1woT"
      },
      "source": [
        "## Cooking up the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OmjwmCtINSTw"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data:\n",
        "\n",
        "from ase import io\n",
        "import os\n",
        "\n",
        "# DATA_DIR = os.path.expanduser(\"~/repos/data/\")\n",
        "# # DATA_DIR = \"/data1/simulations/datasets/rotors/high_temp_ML_training_data/\"\n",
        "# RESULTS_DIR = os.path.expanduser(\"~/repos/data/results\")\n",
        "\n",
        "DATA_DIR = os.path.expanduser(\"/content/drive/MyDrive/data/\")\n",
        "# FANDE_DIR = os.path.expanduser(\"~/\")\n",
        "RESULTS_DIR = os.path.expanduser(\"/content/drive/MyDrive/data/results/\")\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "PREPARE_DATA = False\n",
        "if PREPARE_DATA:\n",
        "        traj_295 = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\":\")\n",
        "        # traj_355 = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_355_355K/md_trajectory.traj\", index=\":\")\n",
        "        traj_295_2000K = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_295_2000K/md_trajectory.traj\", index=\":\")\n",
        "        # traj_355_2000K = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_355_2000K/md_trajectory.traj\", index=\":\")\n",
        "        # traj_295_2000K_forced = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_295_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
        "        # traj_355_2000K_forced = io.read(DATA_DIR+\"/results_triasine_ML_2000/struct_355_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
        "\n",
        "        # trajectory_energy = traj_295[0:5000] + traj_355[0:5000] + traj_295_2000K[0:5000] + traj_355_2000K[0:5000] + traj_295_2000K_forced[0:5000] + traj_355_2000K_forced[0:5000]\n",
        "\n",
        "        train_energy = traj_295[0:5000:10] +  traj_295_2000K[0:5000:10]\n",
        "        train_forces = traj_295_2000K[0:5000:5]\n",
        "        validation_energy = traj_295[1000:1010]\n",
        "        validation_forces = traj_295[1000:1010]\n",
        "\n",
        "        io.write(DATA_DIR+\"/train_energy.traj\", train_energy)\n",
        "        io.write(DATA_DIR+\"/train_forces.traj\", train_forces)\n",
        "        io.write(DATA_DIR+\"/validation_energy.traj\", validation_energy)\n",
        "        io.write(DATA_DIR+\"/validation_forces.traj\", validation_forces)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRz1N5Qq1woU",
        "outputId": "4db8a72b-d41e-4d01-d977-9a40c82c43f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR /content/drive/MyDrive/data/\n",
            "RESULTS_DIR /content/drive/MyDrive/data/results/\n",
            "ENERGY_MODEL variational_inducing_points\n",
            "ENERGY_NUM_INDUCING_POINTS 10\n",
            "ENERGY_LR 0.1\n",
            "ENERGY_NUM_STEPS 5\n",
            "FORCES_MODEL variational_inducing_points\n",
            "FORCES_NUM_INDUCING_POINTS 10\n",
            "NUM_FORCE_SAMPLES 10\n",
            "FORCES_LR 0.1\n",
            "FORCES_NUM_STEPS 5\n",
            "PREDICTOR_NAME test.pth\n",
            "5 5\n",
            "fande.models module imported...\n",
            "Icecream logger is not available\n",
            "Total number of found groups: 14\n",
            "Checking if all atoms are covered:  True\n",
            "Preparing dataloaders...\n",
            "Total length of traj is 5\n",
            "Total number of batches 5\n",
            "Calculating invariants on trajectory with librascal...\n",
            "100% 5/5 [00:00<00:00, 17.94it/s]\n",
            "invariants for energy fitting calculated\n",
            "100% 5/5 [00:08<00:00,  1.75s/it]\n",
            "invariants for forces fitting calculated\n",
            "torch.Size([5, 1200])\n",
            "torch.Size([5])\n",
            "Dataloader for group 0 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 1 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 2 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 3 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 4 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 5 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 6 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 7 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 8 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 9 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 10 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 11 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 12 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloader for group 13 created\n",
            "Number of samples in dataloader: 10\n",
            "Dataloaders ready\n",
            "Seed set to 42\n",
            "Training with inducing points:  torch.Size([5, 1200])\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Training energy model\n",
            "Missing logger folder: /content/lightning_logs\n",
            "2023-12-31 14:22:25.543755: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-31 14:22:25.543836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-31 14:22:25.546317: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-31 14:22:27.168050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 7.2 K \n",
            "2 | mll        | PredictiveLogLikelihood | 7.2 K \n",
            "-------------------------------------------------------\n",
            "7.2 K     Trainable params\n",
            "0         Non-trainable params\n",
            "7.2 K     Total params\n",
            "0.029     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 64.48it/s, v_num=0, loss=1.120]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 47.81it/s, v_num=0, loss=1.120]\n",
            "Energy model fitted\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Training with inducing points:  torch.Size([10, 1200])\n",
            "ModelForces initialized\n",
            "Seed set to 42\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Training force model 0 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 65.78it/s, v_num=1, loss=1.980]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 47.32it/s, v_num=1, loss=1.980]\n",
            "Training force model 1 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 62.45it/s, v_num=2, loss=1.460]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 45.76it/s, v_num=2, loss=1.460]\n",
            "Training force model 2 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 63.37it/s, v_num=3, loss=2.520]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 43.53it/s, v_num=3, loss=2.520]\n",
            "Training force model 3 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 52.94it/s, v_num=4, loss=1.720]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 38.85it/s, v_num=4, loss=1.720]\n",
            "Training force model 4 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 52.37it/s, v_num=5, loss=2.430]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 39.31it/s, v_num=5, loss=2.430]\n",
            "Training force model 5 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 56.39it/s, v_num=6, loss=2.070]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 41.38it/s, v_num=6, loss=2.070]\n",
            "Training force model 6 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 64.34it/s, v_num=7, loss=2.330]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 46.79it/s, v_num=7, loss=2.330]\n",
            "Training force model 7 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 61.95it/s, v_num=8, loss=1.170]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 45.07it/s, v_num=8, loss=1.170]\n",
            "Training force model 8 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 60.51it/s, v_num=9, loss=2.490]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 44.54it/s, v_num=9, loss=2.490]\n",
            "Training force model 9 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 61.33it/s, v_num=10, loss=1.430]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 45.13it/s, v_num=10, loss=1.430]\n",
            "Training force model 10 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 64.97it/s, v_num=11, loss=1.390]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 46.92it/s, v_num=11, loss=1.390]\n",
            "Training force model 11 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 57.75it/s, v_num=12, loss=2.110]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 40.62it/s, v_num=12, loss=2.110]\n",
            "Training force model 12 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 64.67it/s, v_num=13, loss=2.440]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 46.39it/s, v_num=13, loss=2.440]\n",
            "Training force model 13 (Total 14 models)\n",
            "\n",
            "  | Name       | Type                    | Params\n",
            "-------------------------------------------------------\n",
            "0 | likelihood | GaussianLikelihood      | 1     \n",
            "1 | model      | SVGPModel               | 13.3 K\n",
            "2 | mll        | PredictiveLogLikelihood | 13.3 K\n",
            "-------------------------------------------------------\n",
            "13.3 K    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 K    Total params\n",
            "0.053     Total estimated model params size (MB)\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 52.64it/s, v_num=14, loss=2.020]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 1/1 [00:00<00:00, 39.19it/s, v_num=14, loss=2.020]\n",
            "Saving predictor requires humongous amount of memory! Spare some dozens of GBs!\n",
            "  0% 0/10 [00:00<?, ?it/s]Time for invariants (call from forces):  1612.6928329467773\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.18787384033203125\n",
            "Time prediction:  16.082763671875\n",
            "Time moving on device:  1.0421276092529297\n",
            "Time total:  25.111675262451172\n",
            "[[0.27419674 0.26470649 0.20206934]\n",
            " [0.04438817 0.04676718 0.05673074]\n",
            " [0.27291816 0.11050884 0.09750284]\n",
            " ...\n",
            " [0.31766939 0.25504267 0.31879425]\n",
            " [0.24895686 0.32716411 0.35924718]\n",
            " [0.31616646 0.32577476 0.25361881]]\n",
            "[[3.22916365 3.33295965 3.42168045]\n",
            " [3.16692066 3.18884754 3.13940859]\n",
            " [3.55388832 2.81593561 3.26388073]\n",
            " ...\n",
            " [1.20537841 1.1469034  1.26993179]\n",
            " [1.12661433 1.18033409 1.25127602]\n",
            " [1.26882792 1.19490266 1.14961338]]\n",
            "[-3101.256]\n",
            " 10% 1/10 [00:01<00:15,  1.76s/it]Time for invariants (call from forces):  1630.150556564331\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.15854835510253906\n",
            "Time prediction:  3.773212432861328\n",
            "Time moving on device:  0.7343292236328125\n",
            "Time total:  12.486696243286133\n",
            "[[0.27284986 0.26495183 0.20078446]\n",
            " [0.04456972 0.04595017 0.06531432]\n",
            " [0.2738027  0.11122758 0.09695376]\n",
            " ...\n",
            " [0.31829643 0.25624669 0.32148919]\n",
            " [0.2474471  0.31926906 0.35209951]\n",
            " [0.31511855 0.3230606  0.25270858]]\n",
            "[[3.2274642  3.33326721 3.41930342]\n",
            " [3.16696119 3.18587399 3.09835291]\n",
            " [3.55431175 2.80543375 3.26441002]\n",
            " ...\n",
            " [1.20554531 1.14743733 1.27105415]\n",
            " [1.12599874 1.17108607 1.26521063]\n",
            " [1.26833105 1.1969831  1.14942336]]\n",
            "[-3101.2507]\n",
            " 20% 2/10 [00:03<00:13,  1.74s/it]Time for invariants (call from forces):  1600.9469032287598\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.209808349609375\n",
            "Time prediction:  4.837751388549805\n",
            "Time moving on device:  0.9162425994873047\n",
            "Time total:  9.691238403320312\n",
            "[[0.27022335 0.26232755 0.21752103]\n",
            " [0.04466306 0.04507351 0.07344326]\n",
            " [0.2750074  0.11149988 0.09663441]\n",
            " ...\n",
            " [0.31927824 0.257249   0.32423833]\n",
            " [0.25053352 0.32954848 0.35512346]\n",
            " [0.32342136 0.3125501  0.25042379]]\n",
            "[[3.26928282 3.38614511 3.46854782]\n",
            " [3.16671991 3.18337679 3.04632854]\n",
            " [3.55465174 2.80219269 3.26488209]\n",
            " ...\n",
            " [1.2054131  1.14787173 1.27188754]\n",
            " [1.12818003 1.18426394 1.26049137]\n",
            " [1.26367044 1.20418847 1.14475048]]\n",
            "[-3101.2468]\n",
            " 30% 3/10 [00:05<00:12,  1.73s/it]Time for invariants (call from forces):  1633.382797241211\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.1900196075439453\n",
            "Time prediction:  4.411458969116211\n",
            "Time moving on device:  0.9136199951171875\n",
            "Time total:  6.850481033325195\n",
            "[[0.26755804 0.2476162  0.24334863]\n",
            " [0.04468969 0.04422317 0.08002016]\n",
            " [0.27639472 0.11171886 0.09625348]\n",
            " ...\n",
            " [0.32063293 0.25807938 0.32693106]\n",
            " [0.25023019 0.33423153 0.35553434]\n",
            " [0.32804862 0.30241144 0.24341561]]\n",
            "[[3.29660463 3.51124287 3.47767639]\n",
            " [3.16624117 3.18186331 2.99288988]\n",
            " [3.55504942 2.79927778 3.26552773]\n",
            " ...\n",
            " [1.20510542 1.14822769 1.27245641]\n",
            " [1.13160563 1.20035326 1.25167096]\n",
            " [1.25707245 1.20660448 1.14232421]]\n",
            "[-3101.2415]\n",
            " 40% 4/10 [00:06<00:10,  1.73s/it]Time for invariants (call from forces):  1599.8306274414062\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.1685619354248047\n",
            "Time prediction:  4.640340805053711\n",
            "Time moving on device:  0.9179115295410156\n",
            "Time total:  13.52071762084961\n",
            "[[0.2649003  0.22551239 0.26222247]\n",
            " [0.04457898 0.04350874 0.0859999 ]\n",
            " [0.27785736 0.11186762 0.09579048]\n",
            " ...\n",
            " [0.32206511 0.25859499 0.32927221]\n",
            " [0.25009012 0.33534527 0.35398191]\n",
            " [0.33138222 0.29960337 0.23690289]]\n",
            "[[3.31749058 3.55340385 3.39908171]\n",
            " [3.16559124 3.18118334 2.93324375]\n",
            " [3.5555439  2.79781723 3.26626301]\n",
            " ...\n",
            " [1.20469511 1.14843535 1.27275014]\n",
            " [1.13137615 1.20130789 1.25160205]\n",
            " [1.25418758 1.2067275  1.14296508]]\n",
            "[-3101.237]\n",
            " 50% 5/10 [00:08<00:08,  1.72s/it]Time for invariants (call from forces):  1628.9241313934326\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.1671314239501953\n",
            "Time prediction:  5.113363265991211\n",
            "Time moving on device:  1.1568069458007812\n",
            "Time total:  14.303445816040039\n",
            "[[0.26545611 0.21067014 0.2637935 ]\n",
            " [0.04445209 0.042836   0.09004757]\n",
            " [0.28444424 0.10883509 0.08424044]\n",
            " ...\n",
            " [0.32296297 0.25871301 0.33078414]\n",
            " [0.24863936 0.33245572 0.35257119]\n",
            " [0.33331123 0.29844204 0.22074878]]\n",
            "[[3.27913427 3.53461027 3.38855219]\n",
            " [3.16487312 3.1813159  2.88415527]\n",
            " [3.53859758 2.85393143 3.27720785]\n",
            " ...\n",
            " [1.2043587  1.1484077  1.27287078]\n",
            " [1.12642252 1.18315458 1.25761032]\n",
            " [1.26073575 1.20800304 1.13500416]]\n",
            "[-3101.2395]\n",
            " 60% 6/10 [00:10<00:06,  1.72s/it]Time for invariants (call from forces):  1601.165533065796\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.16021728515625\n",
            "Time prediction:  5.224943161010742\n",
            "Time moving on device:  1.1785030364990234\n",
            "Time total:  14.343500137329102\n",
            "[[0.26551053 0.19964799 0.26515836]\n",
            " [0.0442277  0.04228519 0.0927836 ]\n",
            " [0.29332495 0.10170794 0.06445239]\n",
            " ...\n",
            " [0.32310992 0.25862831 0.33129105]\n",
            " [0.2409323  0.31958795 0.3499465 ]\n",
            " [0.33523288 0.30352962 0.22432956]]\n",
            "[[3.25192833 3.50317001 3.38058281]\n",
            " [3.16403437 3.18196774 2.84443521]\n",
            " [3.49326801 2.95151377 3.22077465]\n",
            " ...\n",
            " [1.20426679 1.14824128 1.27294707]\n",
            " [1.12217343 1.16677868 1.26453614]\n",
            " [1.2636348  1.20722556 1.13510203]]\n",
            "[-3101.248]\n",
            " 70% 7/10 [00:12<00:05,  1.71s/it]Time for invariants (call from forces):  1630.537748336792\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.22530555725097656\n",
            "Time prediction:  5.077362060546875\n",
            "Time moving on device:  1.1820793151855469\n",
            "Time total:  8.073091506958008\n",
            "[[0.26497772 0.19651209 0.26595011]\n",
            " [0.04391268 0.04187794 0.09435   ]\n",
            " [0.2980473  0.09672778 0.05440584]\n",
            " ...\n",
            " [0.32282573 0.25816959 0.33072248]\n",
            " [0.2343581  0.31437567 0.34762251]\n",
            " [0.33615878 0.30776587 0.25219122]]\n",
            "[[3.24464703 3.49048948 3.37798977]\n",
            " [3.16311598 3.18305016 2.81739807]\n",
            " [3.46186781 3.00543118 3.16047001]\n",
            " ...\n",
            " [1.204355   1.14786148 1.27285862]\n",
            " [1.12081659 1.16241574 1.2680068 ]\n",
            " [1.25509214 1.20555806 1.14757633]]\n",
            "[-3101.2607]\n",
            " 80% 8/10 [00:13<00:03,  1.71s/it]Time for invariants (call from forces):  1597.6390838623047\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.1697540283203125\n",
            "Time prediction:  4.472255706787109\n",
            "Time moving on device:  0.8878707885742188\n",
            "Time total:  11.777162551879883\n",
            "[[0.26390591 0.2010899  0.26618207]\n",
            " [0.04354885 0.04174228 0.09523521]\n",
            " [0.29891571 0.09751979 0.0559614 ]\n",
            " ...\n",
            " [0.32207042 0.25754532 0.32918009]\n",
            " [0.23373029 0.32489315 0.34690893]\n",
            " [0.33521175 0.30617183 0.26529801]]\n",
            "[[3.25670815 3.50376892 3.38040543]\n",
            " [3.16207218 3.18463802 2.79830813]\n",
            " [3.46998644 3.00196886 3.18800783]\n",
            " ...\n",
            " [1.20459509 1.14736283 1.27258229]\n",
            " [1.12081671 1.17124474 1.26939893]\n",
            " [1.25515771 1.20500433 1.14681745]]\n",
            "[-3101.2742]\n",
            " 90% 9/10 [00:15<00:01,  1.70s/it]Time for invariants (call from forces):  1607.2285175323486\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.18095970153808594\n",
            "Time prediction:  4.669189453125\n",
            "Time moving on device:  0.9253025054931641\n",
            "Time total:  15.218257904052734\n",
            "[[0.26262358 0.20937653 0.26612392]\n",
            " [0.04322984 0.04191655 0.0954126 ]\n",
            " [0.29549018 0.10375048 0.06950574]\n",
            " ...\n",
            " [0.3209143  0.25687876 0.32698253]\n",
            " [0.23839021 0.33915359 0.34768176]\n",
            " [0.33360603 0.30366546 0.26855573]]\n",
            "[[3.27771521 3.52448988 3.38518763]\n",
            " [3.1611433  3.18657923 2.78894615]\n",
            " [3.51198435 2.937222   3.27310181]\n",
            " ...\n",
            " [1.20484543 1.14678907 1.27199864]\n",
            " [1.12173164 1.19309425 1.26954079]\n",
            " [1.25497603 1.20397222 1.14619064]]\n",
            "[-3101.2852]\n",
            "100% 10/10 [00:17<00:00,  1.71s/it]\n"
          ]
        }
      ],
      "source": [
        "ENERGY_MODEL = 'variational_inducing_points' #'variational_inducing_points', 'exact'\n",
        "ENERGY_NUM_INDUCING_POINTS = 10\n",
        "ENERGY_LR = 0.1\n",
        "ENERGY_NUM_STEPS = 5\n",
        "\n",
        "FORCES_MODEL = 'variational_inducing_points' #'variational_inducing_points', 'exact'\n",
        "FORCES_NUM_INDUCING_POINTS = 10\n",
        "NUM_FORCE_SAMPLES = 10\n",
        "FORCES_LR = 0.1\n",
        "FORCES_NUM_STEPS = 5\n",
        "\n",
        "PREDICTOR_NAME = 'test.pth'\n",
        "SUBSAMPLE = 200 # subsample data to reduce time durings tests\n",
        "\n",
        "! python cook_model.py \\\n",
        "--data_dir $DATA_DIR \\\n",
        "--results_dir $RESULTS_DIR \\\n",
        "--energy_model $ENERGY_MODEL \\\n",
        "--energy_num_inducing_points $ENERGY_NUM_INDUCING_POINTS \\\n",
        "--energy_lr $ENERGY_LR \\\n",
        "--energy_num_steps $ENERGY_NUM_STEPS \\\n",
        "--forces_model $FORCES_MODEL \\\n",
        "--forces_num_inducing_points $FORCES_NUM_INDUCING_POINTS \\\n",
        "--num_force_samples $NUM_FORCE_SAMPLES \\\n",
        "--forces_lr $FORCES_LR \\\n",
        "--forces_num_steps $FORCES_NUM_STEPS \\\n",
        "--predictor_name $PREDICTOR_NAME \\\n",
        "--subsample $SUBSAMPLE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry9M9pUc1woU"
      },
      "source": [
        "## Testing models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q-igKC1a1woV"
      },
      "outputs": [],
      "source": [
        "from ase import io\n",
        "test_traj = io.read(DATA_DIR + \"/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\"1000:1010\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81lptjK31woV",
        "outputId": "71b10a9f-5f16-43f1-de30-6ea92b7bb87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rascal.utils.filter:Warning: skmatter module not found. CUR and FPS filters will be unavailable.\n",
            "WARNING:rascal.utils.filter:Original error:\n",
            "No module named 'skmatter'\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "FANDE_DIR = os.path.expanduser(\"~/repos/\")\n",
        "sys.path.append(FANDE_DIR + \"fande/\")\n",
        "\n",
        "from fande.predict import FandePredictor\n",
        "from fande.ase import FandeCalc\n",
        "# load the predictor:\n",
        "# predictor_loaded = torch.load(RESULTS_DIR + \"/fande_predictor.pth\")\n",
        "predictor_loaded = torch.load(RESULTS_DIR + \"/test.pth\")\n",
        "fande_calc_loaded = FandeCalc(predictor_loaded)\n",
        "device = torch.device('cpu')\n",
        "fande_calc_loaded.predictor.move_models_to_device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc-Rh9361woX",
        "outputId": "626cb45d-0b21-49a1-e1ee-83d2254a81c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n",
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1640.7017707824707\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.1819133758544922\n",
            "Time prediction:  6.583929061889648\n",
            "Time moving on device:  0.9796619415283203\n",
            "Time total:  15.606880187988281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1565.4616355895996\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.16617774963378906\n",
            "Time prediction:  13.920068740844727\n",
            "Time moving on device:  1.1463165283203125\n",
            "Time total:  23.116111755371094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1563.460111618042\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.16546249389648438\n",
            "Time prediction:  28.047800064086914\n",
            "Time moving on device:  0.8566379547119141\n",
            "Time total:  36.94319725036621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1570.4982280731201\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.20360946655273438\n",
            "Time prediction:  5.326271057128906\n",
            "Time moving on device:  1.2269020080566406\n",
            "Time total:  11.520862579345703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1570.7216262817383\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.16880035400390625\n",
            "Time prediction:  4.411935806274414\n",
            "Time moving on device:  0.9202957153320312\n",
            "Time total:  13.209342956542969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1572.3586082458496\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.18596649169921875\n",
            "Time prediction:  4.913091659545898\n",
            "Time moving on device:  1.027822494506836\n",
            "Time total:  13.915777206420898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1565.1326179504395\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.17023086547851562\n",
            "Time prediction:  13.309240341186523\n",
            "Time moving on device:  1.1134147644042969\n",
            "Time total:  22.389888763427734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1562.9172325134277\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.16760826110839844\n",
            "Time prediction:  6.44230842590332\n",
            "Time moving on device:  8.201837539672852\n",
            "Time total:  24.730920791625977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fande:Setting context for descriptors calculation to production\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for invariants (call from forces):  1566.2424564361572\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.21719932556152344\n",
            "Time prediction:  9.682893753051758\n",
            "Time moving on device:  0.9925365447998047\n",
            "Time total:  19.509077072143555\n",
            "Time for invariants (call from forces):  1569.739580154419\n",
            "Predicting forces...\n",
            "Energy model summary: \n",
            "Time invariants:  0.17404556274414062\n",
            "Time prediction:  13.674736022949219\n",
            "Time moving on device:  1.5537738800048828\n",
            "Time total:  23.237228393554688\n"
          ]
        }
      ],
      "source": [
        "forces_true = []\n",
        "forces_predicted = []\n",
        "\n",
        "energy_true = []\n",
        "energy_predicted = []\n",
        "\n",
        "for atoms in test_traj:\n",
        "    forces_true.append(atoms.get_forces())\n",
        "    energy_true.append(atoms.get_potential_energy())\n",
        "    atoms.set_calculator(fande_calc_loaded)\n",
        "    forces_predicted.append(atoms.get_forces())\n",
        "    energy_predicted.append(atoms.get_potential_energy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKCXpyfo1woX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "energy_true = np.array(energy_true)\n",
        "energy_predicted = np.array(energy_predicted)\n",
        "energy_errors = energy_predicted - energy_true\n",
        "\n",
        "forces_true = np.array(forces_true)\n",
        "forces_predicted = np.array(forces_predicted)\n",
        "forces_errors = forces_predicted - forces_true\n",
        "\n",
        "atomic_groups = predictor_loaded.fdm.atomic_groups\n",
        "\n",
        "\n",
        "\n",
        "for ag in atomic_groups:\n",
        "\n",
        "    print(\"Atomic group\", ag)\n",
        "    print(\"F_x\")\n",
        "    print(\"MAE\", np.mean(np.abs(forces_errors[:, ag, 0].flatten())))\n",
        "    print(\"RMSE\", np.sqrt(np.mean(forces_errors[:, ag, 0].flatten()**2)))\n",
        "    print(\"F_y\")\n",
        "    print(\"MAE\", np.mean(np.abs(forces_errors[:, ag, 1].flatten())))\n",
        "    print(\"RMSE\", np.sqrt(np.mean(forces_errors[:, ag, 1].flatten()**2)))\n",
        "    print(\"F_z\")\n",
        "    print(\"MAE\", np.mean(np.abs(forces_errors[:, ag, 2].flatten())))\n",
        "    print(\"RMSE\", np.sqrt(np.mean(forces_errors[:, ag, 2].flatten()**2)))\n",
        "    print(\"E\")\n",
        "    print(\"MAE\", np.mean(np.abs(energy_errors.flatten())))\n",
        "    print(\"RMSE\", np.sqrt(np.mean(energy_errors.flatten()**2)))\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 3))\n",
        "    axs[0].set_title(r\"$F_x$\")\n",
        "    axs[0].plot(np.array(forces_true)[:, ag, 0].flatten(), label=\"true\")\n",
        "    axs[0].plot(np.array(forces_predicted)[:, ag, 0].flatten(), label=\"predicted\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].set_title(r\"$F_y$\")\n",
        "    axs[1].plot(np.array(forces_true)[:, ag, 1].flatten(), label=\"true\")\n",
        "    axs[1].plot(np.array(forces_predicted)[:, ag, 1].flatten(), label=\"predicted\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    axs[2].set_title(r\"$F_z$\")\n",
        "    axs[2].plot(np.array(forces_true)[:, ag, 2].flatten(), label=\"true\")\n",
        "    axs[2].plot(np.array(forces_predicted)[:, ag, 2].flatten(), label=\"predicted\")\n",
        "    axs[2].legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 3))\n",
        "\n",
        "    axs[0].set_title(r\"$F_x$ errors\")\n",
        "    axs[0].hist(forces_errors[:, ag, 0].flatten(), bins=100)\n",
        "\n",
        "    axs[1].set_title(r\"$F_y$ errors\")\n",
        "    axs[1].hist(forces_errors[:, ag, 1].flatten(), bins=100)\n",
        "\n",
        "    axs[2].set_title(r\"$F_z$ errors\")\n",
        "    axs[2].hist(forces_errors[:, ag, 2].flatten(), bins=100)\n",
        "    plt.show()\n",
        "\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n",
        "    axs[0].set_title(r\"$E$ errors\")\n",
        "    axs[0].hist(energy_errors.flatten(), bins=100)\n",
        "\n",
        "    axs[1].set_title(r\"$E$\")\n",
        "    axs[1].plot(energy_true, label=\"true\")\n",
        "    axs[1].plot(energy_predicted, label=\"predicted\")\n",
        "    axs[1].legend()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}