{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit energies and forces (full cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(os.path.expandvars(\"/home/$USER/repos/fande/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "\n",
    "traj_295 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\":\")\n",
    "traj_355 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_355K/md_trajectory.traj\", index=\":\")\n",
    "\n",
    "traj_295_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_295_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K_0075force/md_trajectory.traj\", index=\":\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 30000\n"
     ]
    }
   ],
   "source": [
    "trajectory_forces = traj_295_2000K[0:5000:10]\n",
    "trajectory_forces = trajectory_forces[0::10].copy()\n",
    "\n",
    "trajectory_energy = traj_295[0:5000] + traj_355[0:5000] + traj_295_2000K[0:5000] + traj_355_2000K[0:5000] + traj_295_2000K_forced[0:5000] + traj_355_2000K_forced[0:5000]\n",
    "trajectory_energy = trajectory_energy[::].copy()\n",
    "\n",
    "print(len(trajectory_forces), len(trajectory_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fande.models module imported...\n",
      "Total number of found groups: 14\n",
      "Checking if all atoms are covered:  True\n"
     ]
    }
   ],
   "source": [
    "from fande.data import FandeDataModule\n",
    "from fande.utils.find_atomic_groups import find_atomic_groups\n",
    "\n",
    "\n",
    "soap_params = dict(soap_type=\"PowerSpectrum\",\n",
    "        interaction_cutoff=3.0,\n",
    "        max_radial=3,\n",
    "        max_angular=3,\n",
    "        gaussian_sigma_constant=0.3,\n",
    "        gaussian_sigma_type=\"Constant\",\n",
    "        cutoff_function_type=\"RadialScaling\",\n",
    "        cutoff_smooth_width=0.1, # 0.1 is way better than 0.5\n",
    "        cutoff_function_parameters=\n",
    "                dict(\n",
    "                        rate=1,\n",
    "                        scale=3.5,\n",
    "                        exponent=4\n",
    "                        ),\n",
    "        radial_basis=\"GTO\",\n",
    "        normalize=True, # setting False makes model untrainable\n",
    "        #   optimization=\n",
    "        #         dict(\n",
    "        #                 Spline=dict(\n",
    "        #                    accuracy=1.0e-05\n",
    "        #                 )\n",
    "        #             ),\n",
    "        compute_gradients=True, # for energies gradients are ignored\n",
    "        expansion_by_species_method='structure wise'\n",
    "        )\n",
    "##FOR NOW USE THE SAME SOAP PARAMETERS FOR ENERGY AND FORCES! (that makes sense if you're modeling the MD)\n",
    "\n",
    "sample_snapshot = trajectory_forces[0].copy()\n",
    "fdm = FandeDataModule()\n",
    "atomic_groups = find_atomic_groups(sample_snapshot)\n",
    "train_centers_positions = sum(atomic_groups, []) #list(range(len(atoms)))\n",
    "train_derivatives_positions = sum(atomic_groups, [])#list(range(len(atoms)))\n",
    "fdm.atomic_groups_sample_snapshot = sample_snapshot.copy()\n",
    "fdm.atomic_groups = atomic_groups\n",
    "\n",
    "total_forces_samples_per_group = [3000] * len(atomic_groups)\n",
    "high_forces_samples_per_group = [0] * len(atomic_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of traj is 30000\n",
      "Total number of batches 30000\n",
      "Calculating invariants on trajectory with librascal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [13:40<00:00, 36.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invariants for energy fitting calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:19<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invariants for forces fitting calculated\n",
      "torch.Size([30000, 540])\n",
      "torch.Size([30000])\n",
      "Taking ALL 1800 samples for group 0\n",
      "Dataloader for group 0 created\n",
      "Number of samples in dataloader: 1800\n",
      "Dataloader for group 1 created\n",
      "Number of samples in dataloader: 3000\n",
      "Dataloader for group 2 created\n",
      "Number of samples in dataloader: 3000\n",
      "Taking ALL 1800 samples for group 3\n",
      "Dataloader for group 3 created\n",
      "Number of samples in dataloader: 1800\n",
      "Taking ALL 1800 samples for group 4\n",
      "Dataloader for group 4 created\n",
      "Number of samples in dataloader: 1800\n",
      "Dataloader for group 5 created\n",
      "Number of samples in dataloader: 3000\n",
      "Dataloader for group 6 created\n",
      "Number of samples in dataloader: 3000\n",
      "Dataloader for group 7 created\n",
      "Number of samples in dataloader: 3000\n",
      "Dataloader for group 8 created\n",
      "Number of samples in dataloader: 3000\n",
      "Dataloader for group 9 created\n",
      "Number of samples in dataloader: 3000\n",
      "Taking ALL 1800 samples for group 10\n",
      "Dataloader for group 10 created\n",
      "Number of samples in dataloader: 1800\n",
      "Dataloader for group 11 created\n",
      "Number of samples in dataloader: 3000\n",
      "Taking ALL 1800 samples for group 12\n",
      "Dataloader for group 12 created\n",
      "Number of samples in dataloader: 1800\n",
      "Taking ALL 1800 samples for group 13\n",
      "Dataloader for group 13 created\n",
      "Number of samples in dataloader: 1800\n"
     ]
    }
   ],
   "source": [
    "dataloader_energy, dataloaders_forces = fdm.dataloaders_from_trajectory(\n",
    "                                                                trajectory_energy,\n",
    "                                                                trajectory_forces,\n",
    "                                                                # energies = None,\n",
    "                                                                # forces = None,\n",
    "                                                                atomic_groups = atomic_groups,\n",
    "                                                                centers_positions = train_centers_positions,\n",
    "                                                                derivatives_positions = train_derivatives_positions,\n",
    "                                                                energy_soap_hypers = soap_params,\n",
    "                                                                forces_soap_hypers = soap_params,\n",
    "                                                                total_forces_samples_per_group = total_forces_samples_per_group,\n",
    "                                                                high_force_samples_per_group = high_forces_samples_per_group,\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/dlbox2/anaconda3/envs/fande/lib/python3.10/sit ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RawEnergyModel initialized\n",
      "Training energy model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/dlbox2/anaconda3/envs/fande/lib/python3.10/sit ...\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelEnergy         | 542   \n",
      "2 | mll        | ExactMarginalLogLikelihood | 542   \n",
      "----------------------------------------------------------\n",
      "542       Trainable params\n",
      "0         Non-trainable params\n",
      "542       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d09db192074d08b9a0849f3c78d307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Making energy model\n",
    "\n",
    "from fande.models import EnergyModel\n",
    "\n",
    "hparams = {\n",
    "        'dtype' : 'float32',\n",
    "        'device' : 'gpu',\n",
    "        'energy_model_hparams' : {\n",
    "                'num_epochs' : 100,\n",
    "                'learning_rate' : 0.1,\n",
    "        }\n",
    "        }\n",
    "       \n",
    "Energy_model = EnergyModel(\n",
    "        dataloader_energy,\n",
    "        hparams=hparams)\n",
    "\n",
    "Energy_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fitting forces\n",
    "\n",
    "# from fande.models import ModelForces, GroupModelForces\n",
    "\n",
    "\n",
    "# n_steps_list = [200] * len(atomic_groups)\n",
    "# lr_list = [0.1] * len(atomic_groups)\n",
    "\n",
    "# models_hparams = []\n",
    "# for i in range(len(atomic_groups)):\n",
    "#         model_hparams = {\n",
    "#         'atomic_group' : atomic_groups[i],\n",
    "#         'dtype' : hparams['dtype'],\n",
    "#         'device' : hparams['device'],\n",
    "#         'num_epochs' : n_steps_list[i],\n",
    "#         'learning_rate' : lr_list[i],\n",
    "#         'soap_dim' : dataloaders_forces[i].dataset[0][0].shape[-1],\n",
    "#         'soap_params' : soap_params,\n",
    "#         }\n",
    "#         models_hparams.append(model_hparams)\n",
    "\n",
    "# hparams['per_model_hparams'] = models_hparams # access per_model_hparams by model.model_id\n",
    "# gpu_id = 0\n",
    "\n",
    "\n",
    "# models_forces = []\n",
    "# for i in range(len(atomic_groups)):\n",
    "#         model = ModelForces(\n",
    "#         train_x = dataloaders_forces[i].dataset[:][0],\n",
    "#         train_y = dataloaders_forces[i].dataset[:][1],\n",
    "#         atomic_group = atomic_groups[i],\n",
    "#         hparams = hparams,\n",
    "#         id=i)\n",
    "#         models_forces.append(model)\n",
    "        \n",
    "# AG_force_model = GroupModelForces(\n",
    "#         models= models_forces,\n",
    "#         train_data_loaders = dataloaders_forces,\n",
    "#         hparams=hparams, \n",
    "#         gpu_id=gpu_id)\n",
    "\n",
    "# AG_force_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdm.test_DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.predict import FandePredictor\n",
    "from fande.ase import FandeCalc\n",
    "\n",
    "# Energy_model = None\n",
    "AG_force_model = None\n",
    "predictor = FandePredictor(\n",
    "        fdm,\n",
    "        AG_force_model,\n",
    "        Energy_model,\n",
    "        hparams,\n",
    "        soap_params\n",
    "        )\n",
    "\n",
    "fande_calc = FandeCalc(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fande.predict import FandePredictor\n",
    "from fande.ase import FandeCalc\n",
    "# load the predictor:\n",
    "predictor_loaded = torch.load(\"/data1/simulations/ML_models/for_SCML/fande_predictor.pth\")\n",
    "fande_calc_loaded = FandeCalc(predictor_loaded)\n",
    "device = torch.device('cpu')\n",
    "fande_calc_loaded.predictor.move_models_to_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictor requires humongous amount of memory! Spare some dozens of GBs!\n"
     ]
    }
   ],
   "source": [
    "fande_calc.save_predictor(\"/data1/simulations/ML_models/for_SCML/fande_predictor.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  435.0893497467041\n",
      "Energy model device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:49<07:23, 49.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy model summary: \n",
      "Time invariants:  0.11038780212402344\n",
      "Time prediction:  48805.416107177734\n",
      "Time moving on device:  0.8413791656494141\n",
      "Time total:  48807.092905044556\n",
      "[-3082.7146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:49<02:44, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  441.5440559387207\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11491775512695312\n",
      "Time prediction:  81.83622360229492\n",
      "Time moving on device:  0.6401538848876953\n",
      "Time total:  83.50181579589844\n",
      "[-3082.8867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:50<01:19, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  437.6063346862793\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11539459228515625\n",
      "Time prediction:  70.79291343688965\n",
      "Time moving on device:  0.6356239318847656\n",
      "Time total:  72.27468490600586\n",
      "[-3082.9563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:50<00:42,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  431.98442459106445\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11515617370605469\n",
      "Time prediction:  69.95201110839844\n",
      "Time moving on device:  0.6406307220458984\n",
      "Time total:  71.43807411193848\n",
      "[-3082.9548]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:51<00:23,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  436.78975105285645\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11301040649414062\n",
      "Time prediction:  69.81992721557617\n",
      "Time moving on device:  0.6432533264160156\n",
      "Time total:  71.31576538085938\n",
      "[-3082.9087]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:51<00:13,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  432.3616027832031\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11396408081054688\n",
      "Time prediction:  69.81706619262695\n",
      "Time moving on device:  0.6537437438964844\n",
      "Time total:  71.31743431091309\n",
      "[-3082.9006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:52<00:07,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  481.8575382232666\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11801719665527344\n",
      "Time prediction:  71.54655456542969\n",
      "Time moving on device:  0.6411075592041016\n",
      "Time total:  73.06885719299316\n",
      "[-3082.9375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:52<00:03,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  433.4549903869629\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11348724365234375\n",
      "Time prediction:  70.30367851257324\n",
      "Time moving on device:  0.6494522094726562\n",
      "Time total:  71.81644439697266\n",
      "[-3082.998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:53<00:01,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  434.5118999481201\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11515617370605469\n",
      "Time prediction:  75.31452178955078\n",
      "Time moving on device:  0.6337165832519531\n",
      "Time total:  76.79963111877441\n",
      "[-3083.074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:53<00:00,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for invariants (call from forces):  433.55536460876465\n",
      "Energy model device:  cpu\n",
      "Energy model summary: \n",
      "Time invariants:  0.11563301086425781\n",
      "Time prediction:  70.34492492675781\n",
      "Time moving on device:  0.6339550018310547\n",
      "Time total:  71.81668281555176\n",
      "[-3083.1294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ase import io\n",
    "from tqdm import tqdm\n",
    "test_traj = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\"1230:1240\")\n",
    "test_traj = test_traj.copy()\n",
    "\n",
    "real_energies = [s.get_potential_energy() for s in test_traj]\n",
    "predicted_energies = []\n",
    "for i in tqdm(range(len(test_traj))):\n",
    "        test_traj[i].calc = fande_calc_loaded\n",
    "        # predicted_energies.append( test_traj[i].get_potential_energy() )\n",
    "        # print(test_traj[i].get_potential_energy() )\n",
    "        # test_traj[i].get_forces()\n",
    "        print(test_traj[i].get_potential_energy() )\n",
    "        # test_traj[i].get_forces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb セル 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#Y261sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_traj[\u001b[39m10\u001b[39;49m]\u001b[39m.\u001b[39mcalc \u001b[39m=\u001b[39m fande_calc\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#Y261sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# predicted_energies.append( test_traj[i].get_potential_energy() )\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#Y261sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(test_traj[i].get_potential_energy() )\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#Y261sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# test_traj[i].get_forces()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#Y261sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(test_traj[\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mget_potential_energy() )\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_traj[10].calc = fande_calc\n",
    "# predicted_energies.append( test_traj[i].get_potential_energy() )\n",
    "# print(test_traj[i].get_potential_energy() )\n",
    "# test_traj[i].get_forces()\n",
    "print(test_traj[10].get_potential_energy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.any(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:07<00:16,  1.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/fande/lib/python3.10/site-packages/ase/atoms.py:788\u001b[0m, in \u001b[0;36mAtoms.get_forces\u001b[0;34m(self, apply_constraint, md)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAtoms object has no calculator.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 788\u001b[0m forces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calc\u001b[39m.\u001b[39;49mget_forces(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m apply_constraint:\n\u001b[1;32m    791\u001b[0m     \u001b[39m# We need a special md flag here because for MD we want\u001b[39;00m\n\u001b[1;32m    792\u001b[0m     \u001b[39m# to skip real constraints but include special \"constraints\"\u001b[39;00m\n\u001b[1;32m    793\u001b[0m     \u001b[39m# Like Hookean.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[39mfor\u001b[39;00m constraint \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstraints:\n",
      "File \u001b[0;32m~/repos/fande/fande/ase/fande_calc.py:155\u001b[0m, in \u001b[0;36mFandeCalc.get_forces\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_forces\u001b[39m(\u001b[39mself\u001b[39m, atoms):\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(atoms)\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/repos/fande/fande/ase/fande_calc.py:152\u001b[0m, in \u001b[0;36mFandeCalc.update\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate(atoms)\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositions \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_positions())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    150\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpbc \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_pbc())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    151\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_cell())\u001b[39m.\u001b[39many()):\n\u001b[0;32m--> 152\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate(atoms)\n",
      "File \u001b[0;32m~/repos/fande/fande/ase/fande_calc.py:111\u001b[0m, in \u001b[0;36mFandeCalc.calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces \u001b[39m=\u001b[39m forces\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces_variance \u001b[39m=\u001b[39m forces_variance\n\u001b[0;32m--> 111\u001b[0m energy, energy_variance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mpredict_energy_single_snapshot_r(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matoms\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m    112\u001b[0m emax,emin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mfdm\u001b[39m.\u001b[39memax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mfdm\u001b[39m.\u001b[39memin\n\u001b[1;32m    113\u001b[0m energy \u001b[39m=\u001b[39m energy\u001b[39m*\u001b[39m(emax\u001b[39m-\u001b[39memin) \u001b[39m+\u001b[39m emin\n",
      "File \u001b[0;32m~/repos/fande/fande/predict/predictor.py:370\u001b[0m, in \u001b[0;36mFandePredictor.predict_energy_single_snapshot_r\u001b[0;34m(self, snapshot)\u001b[0m\n\u001b[1;32m    368\u001b[0m n_atoms \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(snapshot)            \n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_calculated_snapshot\u001b[39m.\u001b[39mpositions \u001b[39m!=\u001b[39m snapshot\u001b[39m.\u001b[39mpositions):\n\u001b[0;32m--> 370\u001b[0m     X, DX_grouped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfdm\u001b[39m.\u001b[39;49mcalculate_snapshot_invariants_librascal(snapshot)\n\u001b[1;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_calculated_snapshot \u001b[39m=\u001b[39m snapshot\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    372\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_DX_grouped \u001b[39m=\u001b[39m X, DX_grouped\n",
      "File \u001b[0;32m~/repos/fande/fande/data/data_module.py:487\u001b[0m, in \u001b[0;36mFandeDataModule.calculate_snapshot_invariants_librascal\u001b[0;34m(self, snapshot, same_centers_derivatives)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_snapshot_invariants_librascal\u001b[39m(\n\u001b[1;32m    482\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    483\u001b[0m         snapshot: ase\u001b[39m.\u001b[39mAtoms, \n\u001b[1;32m    484\u001b[0m         same_centers_derivatives\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    486\u001b[0m     traj \u001b[39m=\u001b[39m [snapshot]\n\u001b[0;32m--> 487\u001b[0m     snap_X, snap_DX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_invariants_librascal(\n\u001b[1;32m    488\u001b[0m         trajectory\u001b[39m=\u001b[39;49mtraj, \n\u001b[1;32m    489\u001b[0m         same_centers_derivatives\u001b[39m=\u001b[39;49msame_centers_derivatives, \n\u001b[1;32m    490\u001b[0m         calculation_context\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mproduction\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    492\u001b[0m     \u001b[39mreturn\u001b[39;00m snap_X, snap_DX\n",
      "File \u001b[0;32m~/repos/fande/fande/data/data_module.py:351\u001b[0m, in \u001b[0;36mFandeDataModule.calculate_invariants_librascal\u001b[0;34m(self, soap_params, atomic_groups, centers_positions, derivatives_positions, same_centers_derivatives, frames_per_batch, calculation_context, trajectory)\u001b[0m\n\u001b[1;32m    348\u001b[0m traj_b \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mtraj\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    349\u001b[0m forces_b \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mforces\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 351\u001b[0m managers \u001b[39m=\u001b[39m soap\u001b[39m.\u001b[39;49mtransform(traj_b)\n\u001b[1;32m    352\u001b[0m soap_array \u001b[39m=\u001b[39m managers\u001b[39m.\u001b[39mget_features(soap)\n\u001b[1;32m    353\u001b[0m X_np_batched\u001b[39m.\u001b[39mappend(soap_array)\n",
      "File \u001b[0;32m~/anaconda3/envs/fande/lib/python3.10/site-packages/rascal/representations/spherical_invariants.py:341\u001b[0m, in \u001b[0;36mSphericalInvariants.transform\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frames, AtomsList):\n\u001b[1;32m    339\u001b[0m     frames \u001b[39m=\u001b[39m AtomsList(frames, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnl_options)\n\u001b[0;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_representation\u001b[39m.\u001b[39;49mcompute(frames\u001b[39m.\u001b[39;49mmanagers)\n\u001b[1;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m frames\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test_traj[0].get_forces()\n",
    "for i in tqdm(range(len(test_traj))):\n",
    "        test_traj[i].get_forces()\n",
    "# test_traj[1].get_potential_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(real_energies, label=\"real\")\n",
    "plt.plot(predicted_energies, label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomic group force model is not defined. Cannot predict forces. Returning zeros.\n",
      "[-3080.6099]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "atoms = trajectory_energy[51].copy()\n",
    "\n",
    "atoms.set_calculator(fande_calc)\n",
    "\n",
    "print(atoms.get_potential_energy())\n",
    "print(atoms.get_forces())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictor requires humongous amount of memory! Spare some dozens of GBs!\n"
     ]
    }
   ],
   "source": [
    "fande_calc.save_predictor(\"prrrrr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fande.ase import FandeCalc\n",
    "\n",
    "fande_calc = FandeCalc(None)\n",
    "fande_calc.load_predictor(\"prrrrr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3101.314]\n",
      "[[ 0.00611877  0.02384949 -0.15219116]\n",
      " [-0.02478027  0.02558899  0.43151855]\n",
      " [-0.03694153  0.41552734 -0.02424622]\n",
      " ...\n",
      " [-0.11352539 -0.11639404 -0.04455566]\n",
      " [-0.00396729 -0.03076172 -0.02807617]\n",
      " [ 0.31091309  0.01507568 -0.10125732]]\n"
     ]
    }
   ],
   "source": [
    "atoms = fande_calc.predictor.fdm.traj_train[0]\n",
    "atoms.set_calculator(fande_calc)\n",
    "print(atoms.get_potential_energy())\n",
    "print(atoms.get_forces())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fande_calc_loaded = FandeCalc(predictor_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "atoms = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\"10\")\n",
    "\n",
    "atoms.set_calculator(fande_calc_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atoms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb セル 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m atoms\u001b[39m.\u001b[39mget_potential_energy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlbox2/repos/rotor-gp/code/fit_energies.ipynb#X64sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m atoms\u001b[39m.\u001b[39mget_forces()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atoms' is not defined"
     ]
    }
   ],
   "source": [
    "atoms.get_potential_energy()\n",
    "atoms.get_forces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00688136, 0.00688136, 0.00688136],\n",
       "       [0.00688136, 0.00688136, 0.00688136],\n",
       "       [0.00688136, 0.00688136, 0.00688136],\n",
       "       ...,\n",
       "       [0.16884041, 0.16884041, 0.16884041],\n",
       "       [0.16884041, 0.16884041, 0.16884041],\n",
       "       [0.16884041, 0.16884041, 0.16884041]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see when the benefit appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 10, 40_000)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cpu\") \n",
    "\n",
    "model = model.to(dev)\n",
    "likelihood = likelihood.to(dev)\n",
    "train_x = train_x.to(dev)\n",
    "train_y = train_y.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/5 - Loss: -0.175   lengthscale: 0.133   noise: 0.049\n",
      "Iter 2/5 - Loss: -0.178   lengthscale: 0.121   noise: 0.044\n",
      "Iter 3/5 - Loss: -0.178   lengthscale: 0.110   noise: 0.040\n",
      "Iter 4/5 - Loss: -0.177   lengthscale: 0.101   noise: 0.037\n",
      "Iter 5/5 - Loss: -0.169   lengthscale: 0.092   noise: 0.035\n",
      "CPU times: user 30min 57s, sys: 3min 43s, total: 34min 40s\n",
      "Wall time: 10min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 5\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cpu\") \n",
    "\n",
    "model = model.to(dev)\n",
    "likelihood = likelihood.to(dev)\n",
    "test_x = torch.rand(1_0).to(dev)\n",
    "\n",
    "train_x = train_x.to(dev)\n",
    "train_y = train_y.to(dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "model.eval()\n",
    "likelihood.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 20s, sys: 21.5 s, total: 12min 41s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
