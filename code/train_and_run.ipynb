{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python --RegexRemovePreprocessor.patterns=\"^%\"  train_and_run.ipynb\n",
    "\n",
    "# RULES:\n",
    "# 1. Do not make plot.show() only plot.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # https://docs.wandb.ai/guides/sweeps/walkthrough\n",
    "\n",
    "import os\n",
    "machine_name = os.uname()[1]\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project=\"rotor-gp\", save_code=True, notes=\"hello\", id=machine_name, mode='disabled')\n",
    "\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random',\n",
    "#     'metric': \n",
    "#     {\n",
    "#         'goal': 'minimize', \n",
    "#         'name': 'score'\n",
    "#         },\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         'x': {'max': 0.1, 'min': 0.01},\n",
    "#         'y': {'values': [1, 3, 7]},\n",
    "#      }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hydrogen: \n",
    "ind_H_1 = sorted([117, 119, 123, 125, 135, 137, 116, 118, 122, 124, 134, 136]) \n",
    "ind_H_2 = sorted([115, 121, 127, 129, 133, 139, 132, 138, 126, 128, 114, 120] )\n",
    "ind_H_3 = sorted([130, 131, 140, 141, 142, 143, 144, 145, 164, 165, 166, 167, 192, 193, 206, 207, 250, 251] )\n",
    "ind_H_4 = sorted([146, 148, 150, 147, 149, 151, 152, 154, 156, 153, 155, 157, 158, 160, 162, 159, 161, 163, 168, 170, 172, 169, 171, 173, 174, 176, 178, 175, 177, 179, 180, 182, 184, 181, 183, 185, 186, 188, 190, 187, 189, 191, 194, 196, 198, 195, 197, 199, 200, 202, 204, 201, 203, 205, 208, 210, 212, 209, 211, 213, 214, 216, 218, 215, 217, 219, 220, 222, 224, 221, 223, 225, 226, 228, 230, 227, 229, 231, 232, 234, 236, 233, 235, 237, 238, 240, 242, 239, 241, 243, 244, 246, 248, 245, 247, 249, 252, 254, 256, 253, 255, 257, 258, 260, 262, 259, 261, 263] )\n",
    "\n",
    "#Carbon: \n",
    "ind_C_1 = sorted([6, 8, 10, 7, 9, 11] )\n",
    "ind_C_2 = sorted([18, 26, 44, 19, 27, 45] )\n",
    "ind_C_3 = sorted([24, 28, 16, 20, 42, 46, 17, 21, 25, 29, 43, 47] )\n",
    "ind_C_4 = sorted([30, 34, 14, 22, 40, 48, 15, 23, 31, 35, 41, 49] )\n",
    "ind_C_5 = sorted([12, 13, 32, 33, 38, 39] )\n",
    "ind_C_6 = sorted([36, 50, 64, 37, 51, 65, 52, 54, 80, 53, 55, 81, 62, 74, 96, 63, 75, 97] )\n",
    "ind_C_7 = sorted([56, 60, 57, 61, 68, 72, 69, 73, 66, 70, 67, 71, 78, 84, 79, 85, 58, 59, 88, 90, 89, 91, 86, 87, 92, 94, 93, 95, 76, 77, 82, 83, 98, 100, 99, 101] )\n",
    "\n",
    "#Nytrogen: \n",
    "ind_N_1 = sorted( [102, 103, 104, 105, 106, 107] )\n",
    "\n",
    "#Oxygen: \n",
    "ind_O_1 = sorted( [108, 109, 110, 111, 112, 113] )\n",
    "\n",
    "#Silicon: \n",
    "ind_Si_1 = sorted( [0, 1, 2, 3, 4, 5] )\n",
    "\n",
    "len(ind_C_1 + ind_C_2 + ind_C_3 + ind_C_4 + ind_C_5 + ind_C_6 + ind_C_7) + len(ind_H_1 + ind_H_2 + ind_H_3 + ind_H_4)+ len(ind_N_1)+ len(ind_O_1)+ len(ind_Si_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to directory:  /misc/home/qklmn/repos/rotor-gp/results/train_and_run/2023-07-28_18 22-27_016582\n",
      "Loading training data...\n",
      "Total number of frames is 80\n",
      "Total number of batches is 80\n",
      "Total length of traj is 80\n",
      "Total number of batches 80\n",
      "Calculating invariants on trajectory with librascal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:20<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames is 20\n",
      "Total number of batches is 20\n",
      "Total length of traj is 20\n",
      "Total number of batches 20\n",
      "Calculating invariants on trajectory with librascal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "Group  0\n",
      "-----------\n",
      "Number of training points for group 0:  2880\n",
      "Number of test points for group 0:  720\n",
      "\n",
      "-----------\n",
      "Group  1\n",
      "-----------\n",
      "Number of training points for group 1:  2880\n",
      "Number of test points for group 1:  720\n",
      "\n",
      "-----------\n",
      "Group  2\n",
      "-----------\n",
      "Number of training points for group 2:  4320\n",
      "Number of test points for group 2:  1080\n",
      "\n",
      "-----------\n",
      "Group  3\n",
      "-----------\n",
      "Number of training points for group 3:  25920\n",
      "Number of test points for group 3:  6480\n",
      "\n",
      "-----------\n",
      "Group  4\n",
      "-----------\n",
      "Number of training points for group 4:  1440\n",
      "Number of test points for group 4:  360\n",
      "\n",
      "-----------\n",
      "Group  5\n",
      "-----------\n",
      "Number of training points for group 5:  1440\n",
      "Number of test points for group 5:  360\n",
      "\n",
      "-----------\n",
      "Group  6\n",
      "-----------\n",
      "Number of training points for group 6:  2880\n",
      "Number of test points for group 6:  720\n",
      "\n",
      "-----------\n",
      "Group  7\n",
      "-----------\n",
      "Number of training points for group 7:  2880\n",
      "Number of test points for group 7:  720\n",
      "\n",
      "-----------\n",
      "Group  8\n",
      "-----------\n",
      "Number of training points for group 8:  1440\n",
      "Number of test points for group 8:  360\n",
      "\n",
      "-----------\n",
      "Group  9\n",
      "-----------\n",
      "Number of training points for group 9:  4320\n",
      "Number of test points for group 9:  1080\n",
      "\n",
      "-----------\n",
      "Group  10\n",
      "-----------\n",
      "Number of training points for group 10:  8640\n",
      "Number of test points for group 10:  2160\n",
      "\n",
      "-----------\n",
      "Group  11\n",
      "-----------\n",
      "Number of training points for group 11:  1440\n",
      "Number of test points for group 11:  360\n",
      "\n",
      "-----------\n",
      "Group  12\n",
      "-----------\n",
      "Number of training points for group 12:  1440\n",
      "Number of test points for group 12:  360\n",
      "\n",
      "-----------\n",
      "Group  13\n",
      "-----------\n",
      "Number of training points for group 13:  1440\n",
      "Number of test points for group 13:  360\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# # Construct the argument parser\n",
    "# ap = argparse.ArgumentParser()\n",
    "\n",
    "# # Add the arguments to the parser\n",
    "# ap.add_argument(\"-a\", \"--foperand\", required=True,\n",
    "#    help=\"first operand\")\n",
    "# ap.add_argument(\"-b\", \"--soperand\", required=True,\n",
    "#    help=\"second operand\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# print(args)\n",
    "\n",
    "# print(\"Starting script...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# export R=0; python ./train_and_run.py 2>&1 \n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../fande\") \n",
    "# sys.path.append(\"..\") \n",
    "import fande\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['VASP_PP_PATH'] = \"/home/qklmn/repos/pseudos\"\n",
    "\n",
    "def make_calc_dir():\n",
    "    if os.getcwd()[-4:] != 'code':\n",
    "        os.chdir('../../../code')\n",
    "    dir_name = f'{datetime.now().strftime(\"%Y-%m-%d_%H %M-%S_%f\")}'\n",
    "    dir_name = '../results/train_and_run/' + dir_name\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    abs_dir_path = os.path.abspath(dir_name)\n",
    "    return abs_dir_path\n",
    "\n",
    "temp_dir = make_calc_dir()\n",
    "os.chdir(temp_dir)\n",
    "print(\"Saving data to directory: \", temp_dir)\n",
    "\n",
    "\n",
    "import sys\n",
    "log_file = temp_dir + '/LOG_GPU.log'\n",
    "# sys.stdout = open(log_file, 'w')\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "data_folder = \"/home/qklmn/data/\"\n",
    "# data_folder = \"/data1/simulations/\"\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "# traj_300 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_600 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1500 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1800 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_2100 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# print(len(traj_300), len(traj_600), len(traj_900), len(traj_1200), len(traj_1500), len(traj_1800), len(traj_2100))\n",
    "\n",
    "\n",
    "traj_300 = io.read(data_folder + \"datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_600 = io.read(data_folder + \"datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(data_folder + \"datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(data_folder + \"datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1500 = io.read(data_folder + \"datasets/rotors/different_temperatures/1500/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1800 = io.read(data_folder + \"datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_2100 = io.read(data_folder + \"datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "\n",
    "# for parameter selection purpose:\n",
    "# traj_train = traj_300[100:500:5].copy() #traj_1800.copy() + traj_2100.copy()\n",
    "traj_train = traj_1800[100:500:5].copy()\n",
    "# traj_train = traj_2100.copy()\n",
    "# training_indices = np.sort(  np.arange(0, 500, 5) )  \n",
    "# traj_train = [traj_md[i] for i in training_indices]\n",
    "\n",
    "traj_test = traj_300[400:420].copy()\n",
    "# test_indices = np.sort(  np.random.choice(np.arange(0,92795), 200, replace=False) ) \n",
    "# test_indices = np.sort(  np.arange(400,410,1) ) \n",
    "# traj_test = [traj_md[i] for i in test_indices]\n",
    "\n",
    "\n",
    "\n",
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "## Train data:\n",
    "energies_train = np.zeros(len(traj_train) )\n",
    "forces_train = np.zeros( (len(traj_train), len(traj_train[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_train):\n",
    "    energies_train[i] = snap.get_potential_energy()\n",
    "    forces_train[i] = snap.get_forces()\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train, 'forces': forces_train}\n",
    "## Test data:\n",
    "energies_test = np.zeros(len(traj_test) )\n",
    "forces_test = np.zeros( (len(traj_test), len(traj_test[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_test):\n",
    "    energies_test[i] = snap.get_potential_energy()\n",
    "    forces_test[i] = snap.get_forces()\n",
    "test_data = {'trajectory': traj_test, 'energies': energies_test, 'forces': forces_test}\n",
    "\n",
    "\n",
    "atomic_groups = [ind_H_1, ind_H_2, ind_H_3, ind_H_4, ind_C_1, ind_C_2, ind_C_3, ind_C_4, ind_C_5, ind_C_6, ind_C_7, ind_N_1, ind_O_1, ind_Si_1] \n",
    "\n",
    "train_centers_positions = sum(atomic_groups, []) #list(range(len(atoms)))\n",
    "train_derivatives_positions = sum(atomic_groups, [])#list(range(len(atoms)))\n",
    "\n",
    "# Hyperparameters:\n",
    "hparams = {}\n",
    "\n",
    "# Descriptors parameters:\n",
    "# https://github.com/lab-cosmo/librascal/blob/master/examples/MLIP_example.ipynb\n",
    "soap_params = {\n",
    "    # 'species': [\"H\", \"C\", \"O\", \"N\", \"Si\"],\n",
    "    # 'periodic': True,\n",
    "    'interaction_cutoff': 3.0,\n",
    "    'gaussian_sigma_constant': 0.3,\n",
    "    'max_radial': 4,\n",
    "    'max_angular': 4,\n",
    "    'cutoff_smooth_width': 0.1,\n",
    "    # 'average': \"off\",\n",
    "    # 'crossover': True,\n",
    "    # 'dtype': \"float64\",\n",
    "    # 'n_jobs': 10,\n",
    "    # 'sparse': False,\n",
    "    # 'positions': [7, 11, 15] # ignored\n",
    "}\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, test_data, hparams)\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"train\")\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"test\")\n",
    "\n",
    "\n",
    "\n",
    "for g in range(len(atomic_groups)):\n",
    "    print(\"\\n-----------\")\n",
    "    print(\"Group \", g)\n",
    "    print(\"-----------\")\n",
    "    plt.plot(fdm.train_F[g].cpu()[1::1], linestyle = 'None', marker='o', label='train')\n",
    "    plt.plot(fdm.test_F[g].cpu()[1::1], linestyle = 'None', marker='x', label='test')\n",
    "    plt.savefig(\"tran_test_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.hist(fdm.test_F[g].cpu().numpy())\n",
    "    plt.savefig(\"histogram_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "    print(f\"Number of training points for group {g}: \", fdm.train_DX[g].shape[-2])\n",
    "    print(f\"Number of test points for group {g}: \", fdm.test_DX[g].shape[-2])\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# total_training_random_samples = 10\n",
    "# high_force_samples = 5\n",
    "# random_samples = total_training_random_samples - high_force_samples\n",
    "\n",
    "# indices_high_force = torch.concat( \n",
    "#     (torch.topk(fdm.test_F[0], high_force_samples//2, largest=True)[1],  \n",
    "#      torch.topk(fdm.test_F[0], high_force_samples//2, largest=False)[1]) ).cpu().numpy()\n",
    "\n",
    "# ind_slice = np.sort(  \n",
    "#     np.random.choice(np.setdiff1d(np.arange(0, fdm.train_F[0].shape[0]), indices_high_force), random_samples, replace=False) )\n",
    "\n",
    "# indices = np.concatenate((ind_slice, indices_high_force))\n",
    "# indices = np.unique(indices)\n",
    "# print(\"High force indices: \", indices_high_force)\n",
    "# print(ind_slice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader for group 0 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 1 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 2 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 3 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 4 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 5 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 6 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 7 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 8 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 9 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 10 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 11 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 12 created\n",
      "Number of samples in dataloader: 1000\n",
      "Dataloader for group 13 created\n",
      "Number of samples in dataloader: 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# seed_everything(42, workers=True)\n",
    "import torch\n",
    "\n",
    "hparams = {\n",
    "    'dtype' : 'float32',\n",
    "    'device' : 'gpu'\n",
    "}\n",
    "\n",
    "\n",
    "per_model_hparams = []\n",
    "\n",
    "train_DX = fdm.train_DX\n",
    "train_F = fdm.train_F\n",
    "test_DX = fdm.test_DX\n",
    "test_F = fdm.test_F\n",
    "\n",
    "\n",
    "\n",
    "### Prepare data loaders and specify how to sample data for each group:\n",
    "total_samples_per_group = [\n",
    "    2_000, # ind_H_1\n",
    "    2_000, # ind_H_2\n",
    "    2_000, # ind_H_3\n",
    "    2_000, # ind_H_4    \n",
    "    2_000, # ind_C_1\n",
    "    2_000, # ind_C_2\n",
    "    2_000, # ind_C_3\n",
    "    2_000, # ind_C_4\n",
    "    2_000, # ind_C_5\n",
    "    2_000, # ind_C_6\n",
    "    2_000, # ind_C_7\n",
    "    2_000, # ind_N_1\n",
    "    2_000, # ind_O_1\n",
    "    2_000, # ind_Si_1 \n",
    "    ]\n",
    "\n",
    "high_force_samples_per_group = [\n",
    "    0, # ind_H_1\n",
    "    0, # ind_H_2\n",
    "    0, # ind_H_3\n",
    "    0, # ind_H_4    \n",
    "    0, # ind_C_1\n",
    "    0, # ind_C_2\n",
    "    0, # ind_C_3\n",
    "    0, # ind_C_4\n",
    "    0, # ind_C_5\n",
    "    0, # ind_C_6\n",
    "    0, # ind_C_7\n",
    "    0, # ind_N_1\n",
    "    0, # ind_O_1\n",
    "    0, # ind_Si_1\n",
    "    ]\n",
    "\n",
    "train_data_loaders = fdm.prepare_train_data_loaders(\n",
    "    total_samples_per_group=total_samples_per_group,\n",
    "    high_force_samples_per_group=high_force_samples_per_group)\n",
    "\n",
    "hparams['train_indices'] = fdm.train_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 0 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 29.27it/s, v_num=70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 22.14it/s, v_num=70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 1 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 34.97it/s, v_num=71]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 25.62it/s, v_num=71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 2 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 33.90it/s, v_num=72]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 24.86it/s, v_num=72]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 3 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 34.38it/s, v_num=73]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 25.31it/s, v_num=73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 4 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 27.14it/s, v_num=74]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 5 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 24.32it/s, v_num=75]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s, v_num=75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 6 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 34.24it/s, v_num=76]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 24.98it/s, v_num=76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 7 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=77]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=77]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 8 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 31.03it/s, v_num=78]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 23.13it/s, v_num=78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 9 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 32.71it/s, v_num=79]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 24.19it/s, v_num=79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 10 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 28.09it/s, v_num=80]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 11 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 29.99it/s, v_num=81]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 23.21it/s, v_num=81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 12 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 34.75it/s, v_num=82]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 25.21it/s, v_num=82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 1.2 K \n",
      "2 | mll        | ExactMarginalLogLikelihood | 1.2 K \n",
      "----------------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 13 (Total 14 models)\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 39.83it/s, v_num=83]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 28.25it/s, v_num=83]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 100\n",
    "lr = 0.04 # 0.04 for ARD\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.INFO) # logging.ERROR to disable or INFO\n",
    "\n",
    "model_H_1_hparams = {\n",
    "    'atomic_group' : ind_H_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[0].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_2_hparams = {\n",
    "    'atomic_group' : ind_H_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_3_hparams = {\n",
    "    'atomic_group' : ind_H_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[2].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_4_hparams = {\n",
    "    'atomic_group' : ind_H_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[3].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_H = [model_H_1_hparams, model_H_2_hparams, model_H_3_hparams, model_H_4_hparams]\n",
    "\n",
    "model_C_1_hparams = {\n",
    "    'atomic_group' : ind_C_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[4].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_2_hparams = {\n",
    "    'atomic_group' : ind_C_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[5].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_3_hparams = {\n",
    "    'atomic_group' : ind_C_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[6].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_4_hparams = {\n",
    "    'atomic_group' : ind_C_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[7].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_5_hparams = {\n",
    "    'atomic_group' : ind_C_5,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[8].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_6_hparams = {\n",
    "    'atomic_group' : ind_C_6,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[9].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_7_hparams = {\n",
    "    'atomic_group' : ind_C_7,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[10].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "\n",
    "hparams_models_C =  [model_C_1_hparams, model_C_2_hparams, model_C_3_hparams, model_C_4_hparams, model_C_5_hparams,  model_C_6_hparams,  model_C_7_hparams]\n",
    "\n",
    "model_N_1_hparams = {\n",
    "    'atomic_group' : ind_N_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[11].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_N =  [model_N_1_hparams]\n",
    "\n",
    "model_O_1_hparams = {\n",
    "    'atomic_group' : ind_O_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[12].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_O =  [model_O_1_hparams]\n",
    "\n",
    "\n",
    "model_Si_1_hparams = {\n",
    "    'atomic_group' : ind_Si_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[13].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_Si =  [model_Si_1_hparams]\n",
    "\n",
    "# model_Si_hparams = {\n",
    "#     'atomic_group' : Si_atoms,\n",
    "#     'dtype' : hparams['dtype'],\n",
    "#     'device' : hparams['device'],\n",
    "#     'num_epochs' : 1, \n",
    "#     'learning_rate' : 0.01,\n",
    "#     'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "#     'soap_params' : soap_params,\n",
    "# }\n",
    "\n",
    "\n",
    "hparams['per_model_hparams'] = [ \n",
    "    model_H_1_hparams,\n",
    "    model_H_2_hparams,\n",
    "    model_H_3_hparams,\n",
    "    model_H_4_hparams, \n",
    "    model_C_1_hparams,\n",
    "    model_C_2_hparams,\n",
    "    model_C_3_hparams,\n",
    "    model_C_4_hparams,\n",
    "    model_C_5_hparams,\n",
    "    model_C_6_hparams,\n",
    "    model_C_7_hparams,\n",
    "    model_N_1_hparams,\n",
    "    model_O_1_hparams,\n",
    "    model_Si_1_hparams\n",
    "    ] # access per_model_hparams by model.model_id\n",
    "\n",
    "hparams['soap_dim'] = fdm.train_DX[0].shape[-1]\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "from fande.models import ModelForces, GroupModelForces, ModelEnergies, MyCallbacks\n",
    "\n",
    "model_H_1 = ModelForces(\n",
    "    train_x = train_data_loaders[0].dataset[:][0],\n",
    "    train_y = train_data_loaders[0].dataset[:][1],\n",
    "    atomic_group = ind_H_1,\n",
    "    hparams = hparams,\n",
    "    id=0)\n",
    "\n",
    "model_H_2 = ModelForces(\n",
    "    train_x = train_data_loaders[1].dataset[:][0],\n",
    "    train_y = train_data_loaders[1].dataset[:][1],\n",
    "    atomic_group = ind_H_2,\n",
    "    hparams = hparams,\n",
    "    id=1)\n",
    "\n",
    "model_H_3 = ModelForces(\n",
    "    train_x = train_data_loaders[2].dataset[:][0],\n",
    "    train_y = train_data_loaders[2].dataset[:][1],\n",
    "    atomic_group = ind_H_3,\n",
    "    hparams = hparams,\n",
    "    id=2)\n",
    "\n",
    "model_H_4 = ModelForces(\n",
    "    train_x = train_data_loaders[3].dataset[:][0],\n",
    "    train_y = train_data_loaders[3].dataset[:][1],\n",
    "    atomic_group = ind_H_4,\n",
    "    hparams = hparams,\n",
    "    id=3)\n",
    "\n",
    "\n",
    "\n",
    "model_C_1 = ModelForces(\n",
    "    train_x = train_data_loaders[4].dataset[:][0],\n",
    "    train_y = train_data_loaders[4].dataset[:][1],\n",
    "    atomic_group = ind_C_1,\n",
    "    hparams = hparams,\n",
    "    id=4)\n",
    "\n",
    "model_C_2 = ModelForces(\n",
    "    train_x = train_data_loaders[5].dataset[:][0],\n",
    "    train_y = train_data_loaders[5].dataset[:][1],\n",
    "    atomic_group = ind_C_2,\n",
    "    hparams = hparams,\n",
    "    id=5)\n",
    "\n",
    "model_C_3 = ModelForces(\n",
    "    train_x = train_data_loaders[6].dataset[:][0],\n",
    "    train_y = train_data_loaders[6].dataset[:][1],\n",
    "    atomic_group = ind_C_3,\n",
    "    hparams = hparams,\n",
    "    id=6)\n",
    "\n",
    "model_C_4 = ModelForces(\n",
    "    train_x = train_data_loaders[7].dataset[:][0],\n",
    "    train_y = train_data_loaders[7].dataset[:][1],\n",
    "    atomic_group = ind_C_4,\n",
    "    hparams = hparams,\n",
    "    id=7)\n",
    "\n",
    "model_C_5 = ModelForces(\n",
    "    train_x = train_data_loaders[8].dataset[:][0],\n",
    "    train_y = train_data_loaders[8].dataset[:][1],\n",
    "    atomic_group = ind_C_5,\n",
    "    hparams = hparams,\n",
    "    id=8)\n",
    "\n",
    "model_C_6 = ModelForces(\n",
    "    train_x = train_data_loaders[9].dataset[:][0],\n",
    "    train_y = train_data_loaders[9].dataset[:][1],\n",
    "    atomic_group = ind_C_6,\n",
    "    hparams = hparams,\n",
    "    id=9)\n",
    "\n",
    "model_C_7 = ModelForces(\n",
    "    train_x = train_data_loaders[10].dataset[:][0],\n",
    "    train_y = train_data_loaders[10].dataset[:][1],\n",
    "    atomic_group = ind_C_7,\n",
    "    hparams = hparams,\n",
    "    id=10)\n",
    "\n",
    "\n",
    "\n",
    "model_N_1 = ModelForces(\n",
    "    train_x = train_data_loaders[11].dataset[:][0],\n",
    "    train_y = train_data_loaders[11].dataset[:][1],\n",
    "    atomic_group = ind_N_1,\n",
    "    hparams = hparams,\n",
    "    id=11)\n",
    "\n",
    "\n",
    "model_O_1 = ModelForces(\n",
    "    train_x = train_data_loaders[12].dataset[:][0],\n",
    "    train_y = train_data_loaders[12].dataset[:][1],\n",
    "    atomic_group = ind_O_1,\n",
    "    hparams = hparams,\n",
    "    id=12)\n",
    "\n",
    "model_Si_1 = ModelForces(\n",
    "    train_x = train_data_loaders[13].dataset[:][0],\n",
    "    train_y = train_data_loaders[13].dataset[:][1],\n",
    "    atomic_group = ind_Si_1,\n",
    "    hparams = hparams,\n",
    "    id=13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AG_force_model = GroupModelForces(\n",
    "    models= [\n",
    "        model_H_1, \n",
    "        model_H_2, \n",
    "        model_H_3, \n",
    "        model_H_4, \n",
    "        model_C_1, \n",
    "        model_C_2, \n",
    "        model_C_3, \n",
    "        model_C_4, \n",
    "        model_C_5,\n",
    "        model_C_6, \n",
    "        model_C_7, \n",
    "        model_N_1,\n",
    "        model_O_1, \n",
    "        model_Si_1,\n",
    "        ], # model_N, model_O, model_Si],\n",
    "    train_data_loaders = train_data_loaders,\n",
    "    hparams=hparams)\n",
    "\n",
    "AG_force_model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error metrics for atomic group  0\n",
      "RMSE:  0.09770523\n",
      "MAE:  0.07837522\n",
      "Max error:  0.39182746\n",
      "Error metrics for atomic group  1\n",
      "RMSE:  0.08833616\n",
      "MAE:  0.06408477\n",
      "Max error:  0.36701405\n",
      "Error metrics for atomic group  2\n",
      "RMSE:  0.13483393\n",
      "MAE:  0.099908054\n",
      "Max error:  0.5300663\n",
      "Error metrics for atomic group  3\n",
      "RMSE:  0.123174824\n",
      "MAE:  0.09588826\n",
      "Max error:  0.6321881\n",
      "Error metrics for atomic group  4\n",
      "RMSE:  0.16772714\n",
      "MAE:  0.13724777\n",
      "Max error:  0.41641864\n",
      "Error metrics for atomic group  5\n",
      "RMSE:  0.12334558\n",
      "MAE:  0.09246492\n",
      "Max error:  0.3876931\n",
      "Error metrics for atomic group  6\n",
      "RMSE:  0.15096775\n",
      "MAE:  0.12789066\n",
      "Max error:  0.42635006\n",
      "Error metrics for atomic group  7\n",
      "RMSE:  0.1705176\n",
      "MAE:  0.13659224\n",
      "Max error:  0.45912263\n",
      "Error metrics for atomic group  8\n",
      "RMSE:  0.18587929\n",
      "MAE:  0.13645515\n",
      "Max error:  0.6317123\n",
      "Error metrics for atomic group  9\n",
      "RMSE:  0.30213955\n",
      "MAE:  0.24196269\n",
      "Max error:  1.0077566\n",
      "Error metrics for atomic group  10\n",
      "RMSE:  0.2289081\n",
      "MAE:  0.17729667\n",
      "Max error:  1.1695706\n",
      "Error metrics for atomic group  11\n",
      "RMSE:  0.13707134\n",
      "MAE:  0.11102356\n",
      "Max error:  0.35363537\n",
      "Error metrics for atomic group  12\n",
      "RMSE:  0.21979941\n",
      "MAE:  0.18791902\n",
      "Max error:  0.60081285\n",
      "Error metrics for atomic group  13\n",
      "RMSE:  0.428116\n",
      "MAE:  0.34223202\n",
      "Max error:  1.027202\n",
      "Analyzing where predictions are the worst...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09770523,\n",
       " 0.08833616,\n",
       " 0.13483393,\n",
       " 0.123174824,\n",
       " 0.16772714,\n",
       " 0.12334558,\n",
       " 0.15096775,\n",
       " 0.1705176,\n",
       " 0.18587929,\n",
       " 0.30213955,\n",
       " 0.2289081,\n",
       " 0.13707134,\n",
       " 0.21979941,\n",
       " 0.428116]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING PREDICITONS ###\n",
    "\n",
    "\n",
    "from fande.predict import PredictorASE\n",
    "\n",
    "model_e = None\n",
    "trainer_e = None\n",
    "\n",
    "AG_force_model.eval()\n",
    "\n",
    "predictor = PredictorASE(\n",
    "            fdm,\n",
    "            model_e,\n",
    "            trainer_e,\n",
    "            AG_force_model,\n",
    "            # trainer_f,\n",
    "            hparams,\n",
    "            soap_params\n",
    ")\n",
    "\n",
    "rmse_per_model, mae_per_model = predictor.test_errors(view_worst_atoms=True)\n",
    "\n",
    "# rmse_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fande.predict import PredictorASE\n",
    "\n",
    "# from fande.ase import FandeCalc\n",
    "\n",
    "\n",
    "\n",
    "# predictor = PredictorASE(\n",
    "#             fdm,\n",
    "#             model_e,\n",
    "#             trainer_e,\n",
    "#             AG_force_model,\n",
    "#             # trainer_f,\n",
    "#             hparams,\n",
    "#             soap_params\n",
    "# )\n",
    "\n",
    "# atoms = traj_test[14].copy()\n",
    "\n",
    "# # predictor.predict_forces_single_snapshot_r(atoms)\n",
    "\n",
    "# atoms = traj_test[5].copy()\n",
    "\n",
    "# atoms.calc = FandeCalc(predictor)\n",
    "\n",
    "# atoms.get_forces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 91\u001b[0m\n\u001b[1;32m     49\u001b[0m dyn \u001b[39m=\u001b[39m VelocityVerlet(\n\u001b[1;32m     50\u001b[0m     atoms,\n\u001b[1;32m     51\u001b[0m     dt \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39munits\u001b[39m.\u001b[39mfs,\n\u001b[1;32m     52\u001b[0m     trajectory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmd_run/md_test.traj\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     logfile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmd_run/md_log.log\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39m# dyn = NPT(\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m#     atoms,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m#     # dt = 0.5*units.fs,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39m#                trajectory='md_run/md_test.traj',\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m#                logfile=\"md_run/md_log.log\")\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m dyn\u001b[39m.\u001b[39;49mrun(\u001b[39m2_000\u001b[39;49m)\n\u001b[1;32m     93\u001b[0m \u001b[39m# # Structure optimization:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# dyn = BFGS(\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m#     atoms,\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m#     trajectory=\"../results/test/md_runs/md_test.traj\",\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m#     logfile=\"../results/test/md_runs/md_log.log\",)\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# dyn.run(fmax=0.1)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m ALL JOBS WITHIN PYTHON SCRIPT ARE DONE! \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/md.py:137\u001b[0m, in \u001b[0;36mMolecularDynamics.run\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Call Dynamics.run and adjust max_steps \"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps \u001b[39m=\u001b[39m steps \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m Dynamics\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/optimize/optimize.py:156\u001b[0m, in \u001b[0;36mDynamics.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    150\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run dynamics algorithm.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[39m    This method will return when the forces on all individual\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m    atoms are less than *fmax* or when the number of steps exceeds\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    *steps*.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mfor\u001b[39;00m converged \u001b[39min\u001b[39;00m Dynamics\u001b[39m.\u001b[39mirun(\u001b[39mself\u001b[39m):\n\u001b[1;32m    157\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m converged\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/optimize/optimize.py:135\u001b[0m, in \u001b[0;36mDynamics.irun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m# run the algorithm until converged or max_steps reached\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverged() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps:\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m     \u001b[39m# compute the next step\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# let the user inspect the step and change things before logging\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[39m# and predicting the next step\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/verlet.py:75\u001b[0m, in \u001b[0;36mVelocityVerlet.step\u001b[0;34m(self, forces)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m# We need to store the momenta on the atoms before calculating\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m# the forces, as in a parallel Asap calculation atoms may\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# migrate during force calculations, and the momenta need to\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m# migrate along with the atoms.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m atoms\u001b[39m.\u001b[39mset_momenta(p, apply_constraint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m forces \u001b[39m=\u001b[39m atoms\u001b[39m.\u001b[39;49mget_forces(md\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     77\u001b[0m \u001b[39m# Second part of RATTLE will be done here:\u001b[39;00m\n\u001b[1;32m     78\u001b[0m atoms\u001b[39m.\u001b[39mset_momenta(atoms\u001b[39m.\u001b[39mget_momenta() \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt \u001b[39m*\u001b[39m forces)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/atoms.py:788\u001b[0m, in \u001b[0;36mAtoms.get_forces\u001b[0;34m(self, apply_constraint, md)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAtoms object has no calculator.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 788\u001b[0m forces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calc\u001b[39m.\u001b[39;49mget_forces(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m apply_constraint:\n\u001b[1;32m    791\u001b[0m     \u001b[39m# We need a special md flag here because for MD we want\u001b[39;00m\n\u001b[1;32m    792\u001b[0m     \u001b[39m# to skip real constraints but include special \"constraints\"\u001b[39;00m\n\u001b[1;32m    793\u001b[0m     \u001b[39m# Like Hookean.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[39mfor\u001b[39;00m constraint \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstraints:\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:188\u001b[0m, in \u001b[0;36mFandeCalc.get_forces\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_forces\u001b[39m(\u001b[39mself\u001b[39m, atoms):\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(atoms)\n\u001b[1;32m    189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:185\u001b[0m, in \u001b[0;36mFandeCalc.update\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate(atoms)\n\u001b[1;32m    182\u001b[0m \u001b[39melif\u001b[39;00m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositions \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_positions())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    183\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpbc \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_pbc())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    184\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_cell())\u001b[39m.\u001b[39many()):\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate(atoms)\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:129\u001b[0m, in \u001b[0;36mFandeCalc.calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    124\u001b[0m stresses \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((natoms, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m    126\u001b[0m \u001b[39m# forces, forces_var = self.predictor.predict_forces_single(self.atoms)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# print(\"Calculating FORCES!\")\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m forces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mpredict_forces_single_snapshot_r(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matoms\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces \u001b[39m=\u001b[39m forces\n\u001b[1;32m    132\u001b[0m \u001b[39m# comparing with supporting calculation\u001b[39;00m\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/predict/predictors_ase.py:605\u001b[0m, in \u001b[0;36mPredictorASE.predict_forces_single_snapshot_r\u001b[0;34m(self, snapshot, atomic_groups)\u001b[0m\n\u001b[1;32m    603\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    604\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), gpytorch\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mfast_pred_var():\n\u001b[0;32m--> 605\u001b[0m     res \u001b[39m=\u001b[39m model(DX_grouped[idx])\n\u001b[1;32m    607\u001b[0m \u001b[39m# predictions_torch = res.mean\u001b[39;00m\n\u001b[1;32m    609\u001b[0m predictions \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/models/forces.py:320\u001b[0m, in \u001b[0;36mModelForces.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute prediction.\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), gpytorch\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mfast_pred_var():\n\u001b[0;32m--> 320\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_)           \n\u001b[1;32m    321\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood(output) \u001b[39m#.mean.cpu().detach().numpy()\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:332\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39m# Make the prediction\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39mwith\u001b[39;00m settings\u001b[39m.\u001b[39mcg_tolerance(settings\u001b[39m.\u001b[39meval_cg_tolerance\u001b[39m.\u001b[39mvalue()):\n\u001b[1;32m    329\u001b[0m     (\n\u001b[1;32m    330\u001b[0m         predictive_mean,\n\u001b[1;32m    331\u001b[0m         predictive_covar,\n\u001b[0;32m--> 332\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_strategy\u001b[39m.\u001b[39;49mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    334\u001b[0m \u001b[39m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    335\u001b[0m predictive_mean \u001b[39m=\u001b[39m predictive_mean\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mbatch_shape, \u001b[39m*\u001b[39mtest_shape)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:272\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    268\u001b[0m     test_test_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :]\n\u001b[1;32m    269\u001b[0m     test_train_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train]\n\u001b[1;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 272\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[1;32m    273\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[1;32m    274\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:288\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mComputes the posterior predictive covariance of a GP\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m:return: The predictive posterior mean of the test points\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m# NOTE TO FUTURE SELF:\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m# GP, and using addmv requires you to to_dense test_train_covar, which is obviously a huge no-no!\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m res \u001b[39m=\u001b[39m (test_train_covar \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_cache\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    289\u001b[0m res \u001b[39m=\u001b[39m res \u001b[39m+\u001b[39m test_mean\n\u001b[1;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:2763\u001b[0m, in \u001b[0;36mLinearOperator.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2762\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__matmul__\u001b[39m(\u001b[39mself\u001b[39m, other: Union[torch\u001b[39m.\u001b[39mTensor, LinearOperator]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[torch\u001b[39m.\u001b[39mTensor, LinearOperator]:\n\u001b[0;32m-> 2763\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatmul(other)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:1742\u001b[0m, in \u001b[0;36mLinearOperator.matmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmatmul_linear_operator\u001b[39;00m \u001b[39mimport\u001b[39;00m MatmulLinearOperator\n\u001b[1;32m   1740\u001b[0m     \u001b[39mreturn\u001b[39;00m MatmulLinearOperator(\u001b[39mself\u001b[39m, other)\n\u001b[0;32m-> 1742\u001b[0m \u001b[39mreturn\u001b[39;00m Matmul\u001b[39m.\u001b[39mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation_tree(), other, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresentation())\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:406\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrepresentation_tree()\n\u001b[1;32m    403\u001b[0m \u001b[39m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m# representation\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_kernel()\u001b[39m.\u001b[39mrepresentation_tree()\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_grad_enabled):\n\u001b[0;32m---> 25\u001b[0m         output \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     temp_active_dims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims\n\u001b[1;32m    354\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(\n\u001b[1;32m    356\u001b[0m         x1,\n\u001b[1;32m    357\u001b[0m         x2,\n\u001b[1;32m    358\u001b[0m         diag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    359\u001b[0m         last_dim_is_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_dim_is_batch,\n\u001b[1;32m    360\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams,\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m temp_active_dims\n\u001b[1;32m    364\u001b[0m \u001b[39m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:524\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    521\u001b[0m     res \u001b[39m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, last_dim_is_batch\u001b[39m=\u001b[39mlast_dim_is_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    522\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     res \u001b[39m=\u001b[39m to_linear_operator(\n\u001b[0;32m--> 524\u001b[0m         \u001b[39msuper\u001b[39;49m(Kernel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x1_, x2_, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/gpytorch/kernels/scale_kernel.py:109\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, diag\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 109\u001b[0m     orig_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_kernel\u001b[39m.\u001b[39;49mforward(x1, x2, diag\u001b[39m=\u001b[39;49mdiag, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    110\u001b[0m     outputscales \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputscale\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m last_dim_is_batch:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### MD with fande calc\n",
    "print('Testing performance with (meta-)dynamics run...')\n",
    "\n",
    "from fande.ase import FandeCalc\n",
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal\n",
    "\n",
    "\n",
    "# from ase.geometry.analysis import Analysis\n",
    "from ase.constraints import FixAtoms, FixBondLengths\n",
    "from ase.optimize import BFGS\n",
    "from ase import units\n",
    "from ase.io import read\n",
    "import logging\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "from ase.md.nptberendsen import NPTBerendsen\n",
    "from ase.md.nvtberendsen import NVTBerendsen\n",
    "\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR) # logging.ERROR to disable or INFO\n",
    "\n",
    "# traj_md = read('../results/test/machine_learning/dftb_opt_1000_six_rings.traj', index=\":\")\n",
    "# traj_opt = read('../results/test/machine_learning/opt.traj', index=\":\")\n",
    "\n",
    "# atoms = fdm.mol_traj[10].copy()\n",
    "# atoms = traj_md[300].copy()\n",
    "# atoms = traj_opt[-1].copy()\n",
    "atoms = traj_test[10].copy()\n",
    "atoms.set_pbc(True)\n",
    "\n",
    "\n",
    "# moving_atoms = sum(atomic_groups, []) \n",
    "# fixed_atoms = list( set(range(264)) - set(moving_atoms) )\n",
    "# fix_atoms = FixAtoms(indices=fixed_atoms)\n",
    "# atoms.set_constraint(fix_atoms)\n",
    "\n",
    "\n",
    "atoms.calc = FandeCalc(predictor)\n",
    "# atoms.calc.set_atomic_groups([rings_carbons, rings_hydrogens], titles=[\"Rings carbons\", \"Rings hydrogens\"])\n",
    "# atoms.calc.set_forces_errors_plot_file(\"../results/test/md_runs/forces_errors.png\", loginterval=1)\n",
    "# atoms.calc = LennardJones()\n",
    "\n",
    "os.makedirs(\"md_run/\", exist_ok=True)\n",
    "\n",
    "# Verlet dynamics:\n",
    "# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
    "# dyn = VelocityVerlet(\n",
    "#     atoms,\n",
    "#     dt = 0.1*units.fs,\n",
    "#     trajectory=\"md_run/md_test.traj\",\n",
    "#     logfile=\"md_run/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPT(\n",
    "#     atoms,\n",
    "#     # dt = 0.5*units.fs,\n",
    "#     timestep=0.1,\n",
    "#     temperature_K=300,\n",
    "#     externalstress=0.0,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPTBerendsen(atoms, timestep=0.1 * units.fs, temperature_K=300,\n",
    "#                    taut=100 * units.fs, pressure_au=1.01325 * units.bar,\n",
    "#                    taup=1000 * units.fs, compressibility=4.57e-5 / units.bar,\n",
    "#                    trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#                    logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# dyn = NVTBerendsen(atoms, 0.5 * units.fs, 300, taut=0.5*1000*units.fs, \n",
    "#                    trajectory=\"md_run/md_test.traj\",   \n",
    "#                    logfile=\"md_run/md_log.log\")\n",
    "\n",
    "# dyn.run(100)\n",
    "\n",
    "# Langevin dynamics:\n",
    "# https://databases.fysik.dtu.dk/ase/tutorials/md/md.html\n",
    "MaxwellBoltzmannDistribution(atoms, temperature_K=300, force_temp=True)\n",
    "dyn = Langevin(atoms, 0.1*fs, \n",
    "               temperature_K=300, #0.1/units.kB, \n",
    "               friction=0.02,\n",
    "        #        fixcm=True, \n",
    "               trajectory='md_run/md_test.traj',\n",
    "               logfile=\"md_run/md_log.log\")\n",
    "\n",
    "dyn.run(100_000)\n",
    "\n",
    "# # Structure optimization:\n",
    "# dyn = BFGS(\n",
    "#     atoms,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "# dyn.run(fmax=0.1)\n",
    "\n",
    "\n",
    "print(\" ALL JOBS WITHIN PYTHON SCRIPT ARE DONE! \")\n",
    "\n",
    "print(\"TIMING: \", time.time()-start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
