{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python --RegexRemovePreprocessor.patterns=\"^%\"  train_and_run.ipynb\n",
    "\n",
    "# RULES:\n",
    "# 1. Do not make plot.show() only plot.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hydrogen: \n",
    "ind_H_1 = [117, 119, 123, 125, 135, 137, 116, 118, 122, 124, 134, 136] \n",
    "ind_H_2 = [115, 121, 127, 129, 133, 139, 132, 138, 126, 128, 114, 120] \n",
    "ind_H_3 = [130, 131, 140, 141, 142, 143, 144, 145, 164, 165, 166, 167, 192, 193, 206, 207, 250, 251] \n",
    "ind_H_4 = [146, 148, 150, 147, 149, 151, 152, 154, 156, 153, 155, 157, 158, 160, 162, 159, 161, 163, 168, 170, 172, 169, 171, 173, 174, 176, 178, 175, 177, 179, 180, 182, 184, 181, 183, 185, 186, 188, 190, 187, 189, 191, 194, 196, 198, 195, 197, 199, 200, 202, 204, 201, 203, 205, 208, 210, 212, 209, 211, 213, 214, 216, 218, 215, 217, 219, 220, 222, 224, 221, 223, 225, 226, 228, 230, 227, 229, 231, 232, 234, 236, 233, 235, 237, 238, 240, 242, 239, 241, 243, 244, 246, 248, 245, 247, 249, 252, 254, 256, 253, 255, 257, 258, 260, 262, 259, 261, 263] \n",
    "\n",
    "#Carbon: \n",
    "ind_C_1 = [6, 8, 10, 7, 9, 11] \n",
    "ind_C_2 = [18, 26, 44, 19, 27, 45] \n",
    "ind_C_3 = [24, 28, 16, 20, 42, 46, 17, 21, 25, 29, 43, 47] \n",
    "ind_C_4 = [30, 34, 14, 22, 40, 48, 15, 23, 31, 35, 41, 49] \n",
    "ind_C_5 = [12, 13, 32, 33, 38, 39] \n",
    "ind_C_6 = [36, 50, 64, 37, 51, 65, 52, 54, 80, 53, 55, 81, 62, 74, 96, 63, 75, 97] \n",
    "ind_C_7 = [56, 60, 57, 61, 68, 72, 69, 73, 66, 70, 67, 71, 78, 84, 79, 85, 58, 59, 88, 90, 89, 91, 86, 87, 92, 94, 93, 95, 76, 77, 82, 83, 98, 100, 99, 101] \n",
    "\n",
    "#Nytrogen: \n",
    "ind_N_1 = [102, 103, 104, 105, 106, 107] \n",
    "\n",
    "#Oxygen: \n",
    "ind_O_1 = [108, 109, 110, 111, 112, 113] \n",
    "\n",
    "#Silicon: \n",
    "ind_Si_1 = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "len(ind_C_1 + ind_C_2 + ind_C_3 + ind_C_4 + ind_C_5 + ind_C_6 + ind_C_7) + len(ind_H_1 + ind_H_2 + ind_H_3 + ind_H_4)+ len(ind_N_1)+ len(ind_O_1)+ len(ind_Si_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fande.models module imported...\n",
      "Saving data to directory:  /misc/home/qklmn/repos/rotor-gp/results/train_and_run/2023-07-26_11 59-19_699718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:02<00:00,  4.13it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# # Construct the argument parser\n",
    "# ap = argparse.ArgumentParser()\n",
    "\n",
    "# # Add the arguments to the parser\n",
    "# ap.add_argument(\"-a\", \"--foperand\", required=True,\n",
    "#    help=\"first operand\")\n",
    "# ap.add_argument(\"-b\", \"--soperand\", required=True,\n",
    "#    help=\"second operand\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# print(args)\n",
    "\n",
    "# print(\"Starting script...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# export R=0; python ./train_and_run.py 2>&1 \n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../fande\") \n",
    "# sys.path.append(\"..\") \n",
    "import fande\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['VASP_PP_PATH'] = \"/home/qklmn/repos/pseudos\"\n",
    "\n",
    "def make_calc_dir():\n",
    "    if os.getcwd()[-4:] != 'code':\n",
    "        os.chdir('../../../code')\n",
    "    dir_name = f'{datetime.now().strftime(\"%Y-%m-%d_%H %M-%S_%f\")}'\n",
    "    dir_name = '../results/train_and_run/' + dir_name\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    abs_dir_path = os.path.abspath(dir_name)\n",
    "    return abs_dir_path\n",
    "\n",
    "temp_dir = make_calc_dir()\n",
    "os.chdir(temp_dir)\n",
    "print(\"Saving data to directory: \", temp_dir)\n",
    "\n",
    "\n",
    "import sys\n",
    "log_file = temp_dir + '/LOG_GPU.log'\n",
    "sys.stdout = open(log_file, 'w')\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "data_folder = \"/home/qklmn/data/\"\n",
    "# data_folder = \"/data1/simulations/\"\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "# traj_300 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_600 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1500 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1800 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_2100 = io.read(\"/data1/simulations/datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# print(len(traj_300), len(traj_600), len(traj_900), len(traj_1200), len(traj_1500), len(traj_1800), len(traj_2100))\n",
    "\n",
    "\n",
    "traj_300 = io.read(data_folder + \"datasets/rotors/different_temperatures/300/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_600 = io.read(data_folder + \"datasets/rotors/different_temperatures/600/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_900 = io.read(data_folder + \"datasets/rotors/different_temperatures/900/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "# traj_1200 = io.read(data_folder + \"datasets/rotors/different_temperatures/1200/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1500 = io.read(data_folder + \"datasets/rotors/different_temperatures/1500/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_1800 = io.read(data_folder + \"datasets/rotors/different_temperatures/1800/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "traj_2100 = io.read(data_folder + \"datasets/rotors/different_temperatures/2100/OUTCAR\", format=\"vasp-out\", index = \":\")\n",
    "\n",
    "traj_train = traj_1800.copy() + traj_2100.copy()\n",
    "# traj_train = traj_2100.copy()\n",
    "# training_indices = np.sort(  np.arange(0, 500, 5) )  \n",
    "# traj_train = [traj_md[i] for i in training_indices]\n",
    "\n",
    "traj_test = traj_300[400:420].copy()\n",
    "# test_indices = np.sort(  np.random.choice(np.arange(0,92795), 200, replace=False) ) \n",
    "# test_indices = np.sort(  np.arange(400,410,1) ) \n",
    "# traj_test = [traj_md[i] for i in test_indices]\n",
    "\n",
    "\n",
    "import os\n",
    "machine_name = os.uname()[1]\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project=\"rotor-gp\", save_code=True, notes=\"hello\", id=machine_name, mode='disabled')\n",
    "\n",
    "\n",
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "## Train data:\n",
    "energies_train = np.zeros(len(traj_train) )\n",
    "forces_train = np.zeros( (len(traj_train), len(traj_train[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_train):\n",
    "    energies_train[i] = snap.get_potential_energy()\n",
    "    forces_train[i] = snap.get_forces()\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train, 'forces': forces_train}\n",
    "## Test data:\n",
    "energies_test = np.zeros(len(traj_test) )\n",
    "forces_test = np.zeros( (len(traj_test), len(traj_test[0]), 3 ) )\n",
    "for i, snap in enumerate(traj_test):\n",
    "    energies_test[i] = snap.get_potential_energy()\n",
    "    forces_test[i] = snap.get_forces()\n",
    "test_data = {'trajectory': traj_test, 'energies': energies_test, 'forces': forces_test}\n",
    "\n",
    "\n",
    "atomic_groups = [ind_H_1, ind_H_2, ind_H_3, ind_H_4, ind_C_1, ind_C_2, ind_C_3, ind_C_4, ind_C_5, ind_C_6, ind_C_7, ind_N_1, ind_O_1, ind_Si_1] \n",
    "\n",
    "train_centers_positions = sum(atomic_groups, []) #list(range(len(atoms)))\n",
    "train_derivatives_positions = sum(atomic_groups, [])#list(range(len(atoms)))\n",
    "\n",
    "# Hyperparameters:\n",
    "hparams = {}\n",
    "\n",
    "# Descriptors parameters:\n",
    "soap_params = {\n",
    "    'species': [\"H\", \"C\", \"O\", \"N\", \"Si\"],\n",
    "    'periodic': True,\n",
    "    'rcut': 3.0,\n",
    "    'sigma': 0.5,\n",
    "    'nmax': 4,\n",
    "    'lmax': 4,\n",
    "    'average': \"off\",\n",
    "    'crossover': True,\n",
    "    'dtype': \"float64\",\n",
    "    'n_jobs': 10,\n",
    "    'sparse': False,\n",
    "    'positions': [7, 11, 15] # ignored\n",
    "}\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, test_data, hparams)\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"train\")\n",
    "\n",
    "fdm.calculate_invariants_librascal(\n",
    "    soap_params,\n",
    "    atomic_groups = atomic_groups,\n",
    "    centers_positions = train_centers_positions, \n",
    "    derivatives_positions = train_derivatives_positions,\n",
    "    same_centers_derivatives=True,\n",
    "    frames_per_batch=1,\n",
    "    calculation_context=\"test\")\n",
    "\n",
    "\n",
    "\n",
    "for g in range(len(atomic_groups)):\n",
    "    print(\"\\n-----------\")\n",
    "    print(\"Group \", g)\n",
    "    print(\"-----------\")\n",
    "    plt.plot(fdm.train_F[g].cpu()[1::1], linestyle = 'None', marker='o', label='train')\n",
    "    plt.plot(fdm.test_F[g].cpu()[1::1], linestyle = 'None', marker='x', label='test')\n",
    "    plt.savefig(\"tran_test_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.hist(fdm.test_F[g].cpu().numpy())\n",
    "    plt.savefig(\"histogram_forces_group_\" + str(g) + \".png\")\n",
    "    plt.close()\n",
    "    print(f\"Number of training points for group {g}: \", fdm.train_DX[g].shape[-2])\n",
    "    print(f\"Number of test points for group {g}: \", fdm.test_DX[g].shape[-2])\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# total_training_random_samples = 10\n",
    "# high_force_samples = 5\n",
    "# random_samples = total_training_random_samples - high_force_samples\n",
    "\n",
    "# indices_high_force = torch.concat( \n",
    "#     (torch.topk(fdm.test_F[0], high_force_samples//2, largest=True)[1],  \n",
    "#      torch.topk(fdm.test_F[0], high_force_samples//2, largest=False)[1]) ).cpu().numpy()\n",
    "\n",
    "# ind_slice = np.sort(  \n",
    "#     np.random.choice(np.setdiff1d(np.arange(0, fdm.train_F[0].shape[0]), indices_high_force), random_samples, replace=False) )\n",
    "\n",
    "# indices = np.concatenate((ind_slice, indices_high_force))\n",
    "# indices = np.unique(indices)\n",
    "# print(\"High force indices: \", indices_high_force)\n",
    "# print(ind_slice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "# seed_everything(42, workers=True)\n",
    "import torch\n",
    "\n",
    "hparams = {\n",
    "    'dtype' : 'float32',\n",
    "    'device' : 'gpu'\n",
    "}\n",
    "\n",
    "\n",
    "per_model_hparams = []\n",
    "\n",
    "train_DX = fdm.train_DX\n",
    "train_F = fdm.train_F\n",
    "test_DX = fdm.test_DX\n",
    "test_F = fdm.test_F\n",
    "\n",
    "\n",
    "\n",
    "### Prepare data loaders and specify how to sample data for each group:\n",
    "total_samples_per_group = [\n",
    "    5_000, # ind_H_1\n",
    "    5_000, # ind_H_2\n",
    "    5_000, # ind_H_3\n",
    "    5_000, # ind_H_4    \n",
    "    5_000, # ind_C_1\n",
    "    5_000, # ind_C_2\n",
    "    5_000, # ind_C_3\n",
    "    5_000, # ind_C_4\n",
    "    5_000, # ind_C_5\n",
    "    5_000, # ind_C_6\n",
    "    5_000, # ind_C_7\n",
    "    5_000, # ind_N_1\n",
    "    5_000, # ind_O_1\n",
    "    5_000, # ind_Si_1 \n",
    "    ]\n",
    "\n",
    "high_force_samples_per_group = [\n",
    "    0, # ind_H_1\n",
    "    0, # ind_H_2\n",
    "    0, # ind_H_3\n",
    "    0, # ind_H_4    \n",
    "    0, # ind_C_1\n",
    "    0, # ind_C_2\n",
    "    0, # ind_C_3\n",
    "    0, # ind_C_4\n",
    "    0, # ind_C_5\n",
    "    0, # ind_C_6\n",
    "    0, # ind_C_7\n",
    "    0, # ind_N_1\n",
    "    0, # ind_O_1\n",
    "    0, # ind_Si_1\n",
    "    ]\n",
    "\n",
    "train_data_loaders = fdm.prepare_train_data_loaders(\n",
    "    total_samples_per_group=total_samples_per_group,\n",
    "    high_force_samples_per_group=high_force_samples_per_group)\n",
    "\n",
    "hparams['train_indices'] = fdm.train_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning:\n",
      "\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_steps = 300\n",
    "lr = 0.01\n",
    "\n",
    "model_H_1_hparams = {\n",
    "    'atomic_group' : ind_H_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[0].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_2_hparams = {\n",
    "    'atomic_group' : ind_H_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_3_hparams = {\n",
    "    'atomic_group' : ind_H_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[2].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_H_4_hparams = {\n",
    "    'atomic_group' : ind_H_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[3].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_H = [model_H_1_hparams, model_H_2_hparams, model_H_3_hparams, model_H_4_hparams]\n",
    "\n",
    "model_C_1_hparams = {\n",
    "    'atomic_group' : ind_C_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[4].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_2_hparams = {\n",
    "    'atomic_group' : ind_C_2,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[5].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_3_hparams = {\n",
    "    'atomic_group' : ind_C_3,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[6].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_4_hparams = {\n",
    "    'atomic_group' : ind_C_4,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[7].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_5_hparams = {\n",
    "    'atomic_group' : ind_C_5,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[8].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_6_hparams = {\n",
    "    'atomic_group' : ind_C_6,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[9].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "model_C_7_hparams = {\n",
    "    'atomic_group' : ind_C_7,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[10].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "\n",
    "hparams_models_C =  [model_C_1_hparams, model_C_2_hparams, model_C_3_hparams, model_C_4_hparams, model_C_5_hparams,  model_C_6_hparams,  model_C_7_hparams]\n",
    "\n",
    "model_N_1_hparams = {\n",
    "    'atomic_group' : ind_N_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[11].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_N =  [model_N_1_hparams]\n",
    "\n",
    "model_O_1_hparams = {\n",
    "    'atomic_group' : ind_O_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[12].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_O =  [model_O_1_hparams]\n",
    "\n",
    "\n",
    "model_Si_1_hparams = {\n",
    "    'atomic_group' : ind_Si_1,\n",
    "    'dtype' : hparams['dtype'],\n",
    "    'device' : hparams['device'],\n",
    "    'num_epochs' : n_steps,\n",
    "    'learning_rate' : lr,\n",
    "    'soap_dim' : fdm.train_DX[13].shape[-1],\n",
    "    'soap_params' : soap_params,\n",
    "}\n",
    "\n",
    "hparams_models_Si =  [model_Si_1_hparams]\n",
    "\n",
    "# model_Si_hparams = {\n",
    "#     'atomic_group' : Si_atoms,\n",
    "#     'dtype' : hparams['dtype'],\n",
    "#     'device' : hparams['device'],\n",
    "#     'num_epochs' : 1, \n",
    "#     'learning_rate' : 0.01,\n",
    "#     'soap_dim' : fdm.train_DX[1].shape[-1],\n",
    "#     'soap_params' : soap_params,\n",
    "# }\n",
    "\n",
    "\n",
    "hparams['per_model_hparams'] = [ \n",
    "    model_H_1_hparams,\n",
    "    model_H_2_hparams,\n",
    "    model_H_3_hparams,\n",
    "    model_H_4_hparams, \n",
    "    model_C_1_hparams,\n",
    "    model_C_2_hparams,\n",
    "    model_C_3_hparams,\n",
    "    model_C_4_hparams,\n",
    "    model_C_5_hparams,\n",
    "    model_C_6_hparams,\n",
    "    model_C_7_hparams,\n",
    "    model_N_1_hparams,\n",
    "    model_O_1_hparams,\n",
    "    model_Si_1_hparams\n",
    "    ] # access per_model_hparams by model.model_id\n",
    "\n",
    "hparams['soap_dim'] = fdm.train_DX[0].shape[-1]\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "from fande.models import ModelForces, GroupModelForces, ModelEnergies, MyCallbacks\n",
    "\n",
    "model_H_1 = ModelForces(\n",
    "    train_x = train_data_loaders[0].dataset[:][0],\n",
    "    train_y = train_data_loaders[0].dataset[:][1],\n",
    "    atomic_group = ind_H_1,\n",
    "    hparams = hparams,\n",
    "    id=0)\n",
    "\n",
    "model_H_2 = ModelForces(\n",
    "    train_x = train_data_loaders[1].dataset[:][0],\n",
    "    train_y = train_data_loaders[1].dataset[:][1],\n",
    "    atomic_group = ind_H_2,\n",
    "    hparams = hparams,\n",
    "    id=1)\n",
    "\n",
    "model_H_3 = ModelForces(\n",
    "    train_x = train_data_loaders[2].dataset[:][0],\n",
    "    train_y = train_data_loaders[2].dataset[:][1],\n",
    "    atomic_group = ind_H_3,\n",
    "    hparams = hparams,\n",
    "    id=2)\n",
    "\n",
    "model_H_4 = ModelForces(\n",
    "    train_x = train_data_loaders[3].dataset[:][0],\n",
    "    train_y = train_data_loaders[3].dataset[:][1],\n",
    "    atomic_group = ind_H_4,\n",
    "    hparams = hparams,\n",
    "    id=3)\n",
    "\n",
    "\n",
    "\n",
    "model_C_1 = ModelForces(\n",
    "    train_x = train_data_loaders[4].dataset[:][0],\n",
    "    train_y = train_data_loaders[4].dataset[:][1],\n",
    "    atomic_group = ind_C_1,\n",
    "    hparams = hparams,\n",
    "    id=4)\n",
    "\n",
    "model_C_2 = ModelForces(\n",
    "    train_x = train_data_loaders[5].dataset[:][0],\n",
    "    train_y = train_data_loaders[5].dataset[:][1],\n",
    "    atomic_group = ind_C_2,\n",
    "    hparams = hparams,\n",
    "    id=5)\n",
    "\n",
    "model_C_3 = ModelForces(\n",
    "    train_x = train_data_loaders[6].dataset[:][0],\n",
    "    train_y = train_data_loaders[6].dataset[:][1],\n",
    "    atomic_group = ind_C_3,\n",
    "    hparams = hparams,\n",
    "    id=6)\n",
    "\n",
    "model_C_4 = ModelForces(\n",
    "    train_x = train_data_loaders[7].dataset[:][0],\n",
    "    train_y = train_data_loaders[7].dataset[:][1],\n",
    "    atomic_group = ind_C_4,\n",
    "    hparams = hparams,\n",
    "    id=7)\n",
    "\n",
    "model_C_5 = ModelForces(\n",
    "    train_x = train_data_loaders[8].dataset[:][0],\n",
    "    train_y = train_data_loaders[8].dataset[:][1],\n",
    "    atomic_group = ind_C_5,\n",
    "    hparams = hparams,\n",
    "    id=8)\n",
    "\n",
    "model_C_6 = ModelForces(\n",
    "    train_x = train_data_loaders[9].dataset[:][0],\n",
    "    train_y = train_data_loaders[9].dataset[:][1],\n",
    "    atomic_group = ind_C_6,\n",
    "    hparams = hparams,\n",
    "    id=9)\n",
    "\n",
    "model_C_7 = ModelForces(\n",
    "    train_x = train_data_loaders[10].dataset[:][0],\n",
    "    train_y = train_data_loaders[10].dataset[:][1],\n",
    "    atomic_group = ind_C_7,\n",
    "    hparams = hparams,\n",
    "    id=10)\n",
    "\n",
    "\n",
    "\n",
    "model_N_1 = ModelForces(\n",
    "    train_x = train_data_loaders[11].dataset[:][0],\n",
    "    train_y = train_data_loaders[11].dataset[:][1],\n",
    "    atomic_group = ind_N_1,\n",
    "    hparams = hparams,\n",
    "    id=11)\n",
    "\n",
    "\n",
    "model_O_1 = ModelForces(\n",
    "    train_x = train_data_loaders[12].dataset[:][0],\n",
    "    train_y = train_data_loaders[12].dataset[:][1],\n",
    "    atomic_group = ind_O_1,\n",
    "    hparams = hparams,\n",
    "    id=12)\n",
    "\n",
    "model_Si_1 = ModelForces(\n",
    "    train_x = train_data_loaders[13].dataset[:][0],\n",
    "    train_y = train_data_loaders[13].dataset[:][1],\n",
    "    atomic_group = ind_Si_1,\n",
    "    hparams = hparams,\n",
    "    id=13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AG_force_model = GroupModelForces(\n",
    "    models= [\n",
    "        model_H_1, \n",
    "        model_H_2, \n",
    "        model_H_3, \n",
    "        model_H_4, \n",
    "        model_C_1, \n",
    "        model_C_2, \n",
    "        model_C_3, \n",
    "        model_C_4, \n",
    "        model_C_5,\n",
    "        model_C_6, \n",
    "        model_C_7, \n",
    "        model_N_1,\n",
    "        model_O_1, \n",
    "        model_Si_1,\n",
    "        ], # model_N, model_O, model_Si],\n",
    "    train_data_loaders = train_data_loaders,\n",
    "    hparams=hparams)\n",
    "\n",
    "AG_force_model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklmn/mambaforge/envs/gpuenv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning:\n",
      "\n",
      "The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 56 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TESTING PREDICITONS ###\n",
    "print('Testing performance with (meta-)dynamics run...')\n",
    "\n",
    "from fande.predict import PredictorASE\n",
    "\n",
    "model_e = None\n",
    "trainer_e = None\n",
    "\n",
    "AG_force_model.eval()\n",
    "\n",
    "predictor = PredictorASE(\n",
    "            fdm,\n",
    "            model_e,\n",
    "            trainer_e,\n",
    "            AG_force_model,\n",
    "            # trainer_f,\n",
    "            hparams,\n",
    "            soap_params\n",
    ")\n",
    "\n",
    "predictor.test_errors(view_worst_atoms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 86\u001b[0m\n\u001b[1;32m     81\u001b[0m MaxwellBoltzmannDistribution(atoms, temperature_K\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m)\n\u001b[1;32m     82\u001b[0m dyn \u001b[39m=\u001b[39m Langevin(atoms, \u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39mfs, temperature_K\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m\u001b[39m/\u001b[39munits\u001b[39m.\u001b[39mkB, friction\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,\n\u001b[1;32m     83\u001b[0m                fixcm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, trajectory\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmd_run/md_test.traj\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     84\u001b[0m                logfile\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmd_run/md_log.log\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m dyn\u001b[39m.\u001b[39;49mrun(\u001b[39m5_000\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m \u001b[39m# # Structure optimization:\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# dyn = BFGS(\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m#     atoms,\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m#     trajectory=\"../results/test/md_runs/md_test.traj\",\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m#     logfile=\"../results/test/md_runs/md_log.log\",)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m# dyn.run(fmax=0.1)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m ALL JOBS WITHIN PYTHON SCRIPT ARE DONE! \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/md.py:137\u001b[0m, in \u001b[0;36mMolecularDynamics.run\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Call Dynamics.run and adjust max_steps \"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps \u001b[39m=\u001b[39m steps \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m Dynamics\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/optimize/optimize.py:156\u001b[0m, in \u001b[0;36mDynamics.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    150\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run dynamics algorithm.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m \u001b[39m    This method will return when the forces on all individual\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m    atoms are less than *fmax* or when the number of steps exceeds\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    *steps*.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mfor\u001b[39;00m converged \u001b[39min\u001b[39;00m Dynamics\u001b[39m.\u001b[39mirun(\u001b[39mself\u001b[39m):\n\u001b[1;32m    157\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m converged\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/optimize/optimize.py:135\u001b[0m, in \u001b[0;36mDynamics.irun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m# run the algorithm until converged or max_steps reached\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverged() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps:\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m     \u001b[39m# compute the next step\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# let the user inspect the step and change things before logging\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[39m# and predicting the next step\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/md/langevin.py:171\u001b[0m, in \u001b[0;36mLangevin.step\u001b[0;34m(self, forces)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m# recalc velocities after RATTLE constraints are applied\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39matoms\u001b[39m.\u001b[39mget_positions() \u001b[39m-\u001b[39m x \u001b[39m-\u001b[39m\n\u001b[1;32m    170\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc5 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meta) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n\u001b[0;32m--> 171\u001b[0m forces \u001b[39m=\u001b[39m atoms\u001b[39m.\u001b[39;49mget_forces(md\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    173\u001b[0m \u001b[39m# Update the velocities\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc1 \u001b[39m*\u001b[39m forces \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasses \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc2 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv \u001b[39m+\u001b[39m\n\u001b[1;32m    175\u001b[0m            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc3 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxi \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc4 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meta)\n",
      "File \u001b[0;32m~/mambaforge/envs/gpuenv/lib/python3.10/site-packages/ase/atoms.py:788\u001b[0m, in \u001b[0;36mAtoms.get_forces\u001b[0;34m(self, apply_constraint, md)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    787\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAtoms object has no calculator.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 788\u001b[0m forces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calc\u001b[39m.\u001b[39;49mget_forces(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m apply_constraint:\n\u001b[1;32m    791\u001b[0m     \u001b[39m# We need a special md flag here because for MD we want\u001b[39;00m\n\u001b[1;32m    792\u001b[0m     \u001b[39m# to skip real constraints but include special \"constraints\"\u001b[39;00m\n\u001b[1;32m    793\u001b[0m     \u001b[39m# Like Hookean.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m     \u001b[39mfor\u001b[39;00m constraint \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstraints:\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:188\u001b[0m, in \u001b[0;36mFandeCalc.get_forces\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_forces\u001b[39m(\u001b[39mself\u001b[39m, atoms):\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(atoms)\n\u001b[1;32m    189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:185\u001b[0m, in \u001b[0;36mFandeCalc.update\u001b[0;34m(self, atoms)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate(atoms)\n\u001b[1;32m    182\u001b[0m \u001b[39melif\u001b[39;00m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositions \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_positions())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    183\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpbc \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_pbc())\u001b[39m.\u001b[39many() \u001b[39mor\u001b[39;00m\n\u001b[1;32m    184\u001b[0m       (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell \u001b[39m!=\u001b[39m atoms\u001b[39m.\u001b[39mget_cell())\u001b[39m.\u001b[39many()):\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate(atoms)\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/ase/fande_calc.py:129\u001b[0m, in \u001b[0;36mFandeCalc.calculate\u001b[0;34m(self, atoms, properties, system_changes)\u001b[0m\n\u001b[1;32m    124\u001b[0m stresses \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((natoms, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m    126\u001b[0m \u001b[39m# forces, forces_var = self.predictor.predict_forces_single(self.atoms)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# print(\"Calculating FORCES!\")\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m forces \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mpredict_forces_single_snapshot_r(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matoms\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforces \u001b[39m=\u001b[39m forces\n\u001b[1;32m    132\u001b[0m \u001b[39m# comparing with supporting calculation\u001b[39;00m\n",
      "File \u001b[0;32m/misc/home/qklmn/repos/rotor-gp/code/../../fande/fande/predict/predictors_ase.py:578\u001b[0m, in \u001b[0;36mPredictorASE.predict_forces_single_snapshot_r\u001b[0;34m(self, snapshot, atomic_groups)\u001b[0m\n\u001b[1;32m    575\u001b[0m trainer_f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mag_force_model\u001b[39m.\u001b[39mtrainers[idx]\n\u001b[1;32m    577\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m res \u001b[39m=\u001b[39m trainer_f\u001b[39m.\u001b[39;49mpredict(model, test_dl)[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    580\u001b[0m predictions_torch \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mmean\n\u001b[1;32m    582\u001b[0m predictions \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%capture o\n",
    "### MD with fande calc\n",
    "from fande.ase import FandeCalc\n",
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal\n",
    "\n",
    "\n",
    "# from ase.geometry.analysis import Analysis\n",
    "from ase.constraints import FixAtoms, FixBondLengths\n",
    "from ase.optimize import BFGS\n",
    "from ase import units\n",
    "from ase.io import read\n",
    "import logging\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.npt import NPT\n",
    "from ase.md.nptberendsen import NPTBerendsen\n",
    "from ase.md.nvtberendsen import NVTBerendsen\n",
    "\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR) # logging.ERROR to disable or INFO\n",
    "\n",
    "# traj_md = read('../results/test/machine_learning/dftb_opt_1000_six_rings.traj', index=\":\")\n",
    "# traj_opt = read('../results/test/machine_learning/opt.traj', index=\":\")\n",
    "\n",
    "# atoms = fdm.mol_traj[10].copy()\n",
    "# atoms = traj_md[300].copy()\n",
    "# atoms = traj_opt[-1].copy()\n",
    "atoms = traj_test[10].copy()\n",
    "atoms.set_pbc(True)\n",
    "\n",
    "\n",
    "moving_atoms = sum(atomic_groups, []) \n",
    "fixed_atoms = list( set(range(264)) - set(moving_atoms) )\n",
    "fix_atoms = FixAtoms(indices=fixed_atoms)\n",
    "atoms.set_constraint(fix_atoms)\n",
    "\n",
    "\n",
    "atoms.calc = FandeCalc(predictor)\n",
    "# atoms.calc.set_atomic_groups([rings_carbons, rings_hydrogens], titles=[\"Rings carbons\", \"Rings hydrogens\"])\n",
    "# atoms.calc.set_forces_errors_plot_file(\"../results/test/md_runs/forces_errors.png\", loginterval=1)\n",
    "# atoms.calc = LennardJones()\n",
    "\n",
    "os.makedirs(\"md_run/\", exist_ok=True)\n",
    "\n",
    "# Verlet dynamics:\n",
    "# MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
    "# dyn = VelocityVerlet(\n",
    "#     atoms,\n",
    "#     dt = 0.5*units.fs,\n",
    "#     trajectory=\"md_run/md_test.traj\",\n",
    "#     logfile=\"md_run/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPT(\n",
    "#     atoms,\n",
    "#     # dt = 0.5*units.fs,\n",
    "#     timestep=0.1,\n",
    "#     temperature_K=300,\n",
    "#     externalstress=0.0,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",\n",
    "# )\n",
    "\n",
    "# dyn = NPTBerendsen(atoms, timestep=0.1 * units.fs, temperature_K=300,\n",
    "#                    taut=100 * units.fs, pressure_au=1.01325 * units.bar,\n",
    "#                    taup=1000 * units.fs, compressibility=4.57e-5 / units.bar,\n",
    "#                    trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#                    logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# dyn = NVTBerendsen(atoms, 0.5 * units.fs, 300, taut=0.5*1000*units.fs, \n",
    "#                    trajectory=\"md_run/md_test.traj\",   \n",
    "#                    logfile=\"md_run/md_log.log\")\n",
    "\n",
    "# dyn.run(100)\n",
    "\n",
    "# Langevin dynamics:\n",
    "# https://databases.fysik.dtu.dk/ase/tutorials/md/md.html\n",
    "MaxwellBoltzmannDistribution(atoms, temperature_K=300)\n",
    "dyn = Langevin(atoms, 0.5*fs, temperature_K=0.1/units.kB, friction=0.1,\n",
    "               fixcm=True, trajectory='md_run/md_test.traj',\n",
    "               logfile=\"md_run/md_log.log\")\n",
    "\n",
    "dyn.run(5_000)\n",
    "\n",
    "# # Structure optimization:\n",
    "# dyn = BFGS(\n",
    "#     atoms,\n",
    "#     trajectory=\"../results/test/md_runs/md_test.traj\",\n",
    "#     logfile=\"../results/test/md_runs/md_log.log\",)\n",
    "# dyn.run(fmax=0.1)\n",
    "\n",
    "\n",
    "print(\" ALL JOBS WITHIN PYTHON SCRIPT ARE DONE! \")\n",
    "\n",
    "print(\"TIMING: \", time.time()-start_time, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.units import Bohr,Rydberg,kJ,kB,fs,Hartree,mol,kcal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
