{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do:\n",
    "\n",
    "0. Rename FandeDataModuleASE into FandeDataModule\n",
    "1. Improve FandeDataModuleASE, initialization with forces and energies\n",
    "2. make parallel calculation of invariants within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expandvars(\"/home/$USER/repos/fande/\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "\n",
    "traj_295 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\":\")\n",
    "traj_355 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_355K/md_trajectory.traj\", index=\":\")\n",
    "\n",
    "traj_295_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_295_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_train = traj_295[0:5000:10] + traj_355[0:5000:10] + traj_295_2000K[0:5000:10] + traj_355_2000K[0:5000:10] + traj_295_2000K_forced[0:5000:10] + traj_355_2000K_forced[0:5000:10]\n",
    "traj_train = traj_295_2000K[1000:5000:5] + traj_355_2000K[1000:5000:5]  \n",
    "traj_train = traj_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_train = [s.get_potential_energy() for s in traj_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to fake the initialization of the fdm\n",
    "# Hyperparameters:\n",
    "hparams = {\n",
    "        'dtype' : 'float32',\n",
    "        'device' : 'gpu'\n",
    "        }\n",
    "\n",
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "## Train data:\n",
    "energies_train = np.zeros(len(traj_train) )\n",
    "forces_train = np.zeros( (len(traj_train), len(traj_train[0]), 3 ) )\n",
    "\n",
    "for i, snap in enumerate(traj_train):\n",
    "        energies_train[i] = snap.get_potential_energy()\n",
    "        forces_train[i] = snap.get_forces()\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train,'trajectory_energies': traj_train, 'forces': forces_train}\n",
    "\n",
    "## Test data:\n",
    "# energies_test = np.zeros(len(traj_test) )\n",
    "# forces_test = np.zeros( (len(traj_test), len(traj_test[0]), 3 ) )\n",
    "# for i, snap in enumerate(traj_test):\n",
    "#         energies_test[i] = snap.get_potential_energy()\n",
    "#         forces_test[i] = snap.get_forces()\n",
    "# test_data = {'trajectory_energies': traj_test, 'energies': energies_test, 'forces': forces_test}\n",
    "\n",
    "test_data={}\n",
    "\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, train_data, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snap_copy = traj_train[0].copy()\n",
    "snap_copy = io.read(\"/data1/simulations/datasets/rotors/simulations_cluster/27_11_2023/27/2023-11-27_17:27:26.502178/md_trajectory.traj\", index=\"0\")\n",
    "\n",
    "from ase.build import make_supercell\n",
    "\n",
    "snap_super = make_supercell(snap_copy, [[1,0,0],[0,1,0],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['/home/dlbox2/anaconda3/envs/fande/bin/pytho...>"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ase.visualize import view\n",
    "\n",
    "view(snap_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snap_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames is 1\n",
      "Total number of batches is 1\n",
      "Total length of traj is 1\n",
      "Total number of batches 1\n",
      "Calculating invariants on trajectory with librascal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 s, sys: 200 ms, total: 2.16 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "# def calculate_invariants_librascal_no_derivatives(\n",
    "#         self,\n",
    "#         trajectory, \n",
    "#         soap_params,\n",
    "#         frames_per_batch=10): \n",
    "\n",
    "# Descriptors parameters:\n",
    "# https://github.com/lab-cosmo/librascal/blob/master/examples/MLIP_example.ipynb\n",
    "# soap_params = {\n",
    "# # 'species': [\"H\", \"C\", \"O\", \"N\", \"Si\"],\n",
    "# 'periodic': True,\n",
    "# 'interaction_cutoff': 3.0,\n",
    "# 'gaussian_sigma_constant': 0.3,\n",
    "# 'max_radial': 5,\n",
    "# 'max_angular': 5,\n",
    "# 'cutoff_smooth_width': 0.1,\n",
    "# # 'average': \"off\",\n",
    "# # 'crossover': True,\n",
    "# # 'dtype': \"float64\",\n",
    "# # 'n_jobs': 10,\n",
    "# # 'sparse': False,\n",
    "# # 'positions': [7, 11, 15] # ignored\n",
    "# }\n",
    "\n",
    "\n",
    "# train_X_np = fdm.calculate_invariants_librascal_no_derivatives(traj_train[0:10], soap_params, frames_per_batch=1)\n",
    "# X = fdm.calculate_invariants_librascal_no_derivatives([snap_super], soap_params, frames_per_batch=1)\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "        interaction_cutoff=3.0,\n",
    "        max_radial=5,\n",
    "        max_angular=5,\n",
    "        gaussian_sigma_constant=0.3,\n",
    "        gaussian_sigma_type=\"Constant\",\n",
    "        cutoff_function_type=\"RadialScaling\",\n",
    "        cutoff_smooth_width=0.1, # 0.1 is way better than 0.5\n",
    "        cutoff_function_parameters=\n",
    "                dict(\n",
    "                        rate=1,\n",
    "                        scale=3.5,\n",
    "                        exponent=4\n",
    "                        ),\n",
    "        radial_basis=\"GTO\",\n",
    "        normalize=True, # setting False makes model untrainable\n",
    "        #   optimization=\n",
    "        #         dict(\n",
    "        #                 Spline=dict(\n",
    "        #                    accuracy=1.0e-05\n",
    "        #                 )\n",
    "        #             ),\n",
    "        compute_gradients=True,\n",
    "        expansion_by_species_method='structure wise'\n",
    "        )\n",
    "        \n",
    "# snap_super.set_pbc([False, False, False])\n",
    "snap_super.set_pbc([True, True, True])\n",
    "# snap_super\n",
    "\n",
    "fdm.soap_hypers = hypers\n",
    "fdm.atomic_groups_train = [list(range(len(snap_super)))]\n",
    "fdm.centers_positions_train = [list(range(len(snap_super)))]\n",
    "fdm.derivatives_positions_train = [list(range(len(snap_super)))]\n",
    "X = fdm.calculate_invariants_librascal_no_derivatives([snap_super], soap_params, frames_per_batch=1)\n",
    "# DX = fdm.calculate_snapshot_invariants_librascal(snap_super, same_centers_derivatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_non_H = []\n",
    "\n",
    "for ind,s in enumerate(traj_train[0].get_chemical_symbols()):\n",
    "        # print(s)\n",
    "        if s != \"H\":\n",
    "                indices_non_H.append(ind)\n",
    "\n",
    "energies_train_normalized = (energies_train - np.min(energies_train))/(np.max(energies_train) - np.min(energies_train))\n",
    "\n",
    "# train_X = X_np[:,indices_non_H,:]\n",
    "train_X = train_X_np\n",
    "\n",
    "# train_X = torch.tensor(X_np_batched)\n",
    "train_X = torch.tensor(train_X.sum(axis=1)).cuda()\n",
    "train_Y = torch.tensor(energies_train_normalized).cuda()\n",
    "\n",
    "print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "from gpytorch.kernels import (\n",
    "    RBFKernel,\n",
    "    ScaleKernel,\n",
    "    LinearKernel,\n",
    "    AdditiveKernel,\n",
    "    MultitaskKernel,\n",
    "    PolynomialKernel,\n",
    "    MaternKernel,\n",
    ")\n",
    "from gpytorch.means import ZeroMean, ConstantMean\n",
    "\n",
    "from gpytorch.models import ExactGP\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/76251549/setting-the-task-covariance-matrix-to-the-correlation-matrix-in-gpytorch\n",
    "\n",
    "class ExactGPModelEnergies(ExactGP):\n",
    "    def __init__(self, train_X, train_Y, likelihood):\n",
    "        super().__init__(\n",
    "            train_X, train_Y, likelihood\n",
    "        )  # the old-style super(ExactGPModel, self) was causing error!\n",
    "        self.mean_module = ConstantMean()\n",
    "\n",
    "        self.soap_dim = train_X.shape[-1]\n",
    "        # self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=self.soap_dim))#LinearKernel()\n",
    "        self.covar_module = ScaleKernel(MaternKernel(ard_num_dims=self.soap_dim))#LinearKernel()\n",
    "        # self.covar_module = ScaleKernel(LinearKernel(ard_num_dims=self.soap_dim))\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = X\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = train_X.cuda()\n",
    "# train_Y = torch.tensor(energies_train_normalized).cuda()\n",
    "# test_X = test_X.cuda()\n",
    "# test_Y = test_Y.cuda()\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModelEnergies(train_X, train_Y, likelihood)\n",
    "# model = ExactGPModelEnergiesMulti(train_X, train_Y, likelihood)\n",
    "model = model.cuda()\n",
    "likelihood = likelihood.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "training_iter = 100\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "print(\"Training...\")\n",
    "# initial_loss = -mll(model(train_X), train_Y).item()\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # print(\"grad zeroed\")\n",
    "    # Output from model\n",
    "    output = model(train_X)\n",
    "    # print(\"Output calculated\")\n",
    "    # print(output)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_Y)\n",
    "    # print(\"Loss calculated, \")\n",
    "\n",
    "    loss.backward()\n",
    "    # print(loss)\n",
    "    # print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "    #     i + 1, training_iter, loss.item(),\n",
    "    #     model.covar_module.base_kernel.lengthscale.item(),\n",
    "    #     model.likelihood.noise.item()\n",
    "    # ))\n",
    "    print(f\"step: {i},loss: {loss}\")\n",
    "    optimizer.step()\n",
    "\n",
    "# print(\"Initial loss: \", initial_loss)\n",
    "print(\"Final loss: \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# edit     def calculate_invariants_librascal_no_derivatives("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "test_x = test_X\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "# with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#     test_x = torch.linspace(0, 1, 51)\n",
    "observed_pred = likelihood(model(test_x)).mean.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(observed_pred, label=\"Predicted energy\")\n",
    "plt.plot(test_Y.detach().cpu().numpy(), label=\"True energy\")\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Predicted Energy')\n",
    "# plt.xlim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_Y)\n",
    "plt.ylabel('Energy')\n",
    "plt.xlabel('step')\n",
    "plt.xlim(85, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_test = io.read(\"/data1/simulations/datasets/rotors/for jacs paper/295_0.075_same_+/md_trajectory.traj\", index=\":\", format=\"traj\")\n",
    "energies_test = [s.get_potential_energy() for s in traj_test]\n",
    "energies_test_normalized = (energies_test - np.min(energies_train))/(np.max(energies_train) - np.min(energies_train))\n",
    "traj = traj_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_np = fdm.calculate_invariants_librascal_no_derivatives(traj_test[0:10], soap_params, frames_per_batch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_non_H = []\n",
    "\n",
    "for ind,s in enumerate(traj[0].get_chemical_symbols()):\n",
    "        # print(s)\n",
    "        if s != \"H\":\n",
    "                indices_non_H.append(ind)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_np_batched = np.array(X_np_batched)\n",
    "E_np_batched = np.array(E_np_batched).flatten()\n",
    "\n",
    "# test_X = X_np_batched[:,indices_non_H,:]\n",
    "test_X = X_np_batched\n",
    "test_X = test_X.sum(axis=1)\n",
    "test_X = torch.tensor(test_X).cuda()\n",
    "test_Y = torch.tensor(energies_test_normalized).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(energies_train_normalized)\n",
    "# plt.plot(energies_test_normalized)\n",
    "plt.plot(test_Y.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafting the energy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.expandvars(\"/home/$USER/repos/fande/\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "\n",
    "traj_295 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\":\")\n",
    "traj_355 = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_355K/md_trajectory.traj\", index=\":\")\n",
    "\n",
    "traj_295_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K/md_trajectory.traj\", index=\":\")\n",
    "traj_295_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_2000K_0075force/md_trajectory.traj\", index=\":\")\n",
    "traj_355_2000K_forced = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_355_2000K_0075force/md_trajectory.traj\", index=\":\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.data import FandeDataModule\n",
    "from fande.utils.find_atomic_groups import find_atomic_groups\n",
    "\n",
    "fdm = FandeDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_forces = traj_295_2000K[0:5000:10]\n",
    "trajectory_forces = trajectory_forces[0:10].copy()\n",
    "trajectory_energy = traj_295[0:5000:10] + traj_355[0:5000:10] + traj_295_2000K[0:5000:10] + traj_355_2000K[0:5000:10] + traj_295_2000K_forced[0:5000:10] + traj_355_2000K_forced[0:5000:10]\n",
    "trajectory_energy = trajectory_energy[0:5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of found groups: 14\n",
      "Checking if all atoms are covered:  True\n"
     ]
    }
   ],
   "source": [
    "soap_params = dict(soap_type=\"PowerSpectrum\",\n",
    "        interaction_cutoff=1.0,\n",
    "        max_radial=1,\n",
    "        max_angular=1,\n",
    "        gaussian_sigma_constant=0.3,\n",
    "        gaussian_sigma_type=\"Constant\",\n",
    "        cutoff_function_type=\"RadialScaling\",\n",
    "        cutoff_smooth_width=0.1, # 0.1 is way better than 0.5\n",
    "        cutoff_function_parameters=\n",
    "                dict(\n",
    "                        rate=1,\n",
    "                        scale=3.5,\n",
    "                        exponent=4\n",
    "                        ),\n",
    "        radial_basis=\"GTO\",\n",
    "        normalize=True, # setting False makes model untrainable\n",
    "        #   optimization=\n",
    "        #         dict(\n",
    "        #                 Spline=dict(\n",
    "        #                    accuracy=1.0e-05\n",
    "        #                 )\n",
    "        #             ),\n",
    "        compute_gradients=True,\n",
    "        expansion_by_species_method='structure wise'\n",
    "        )\n",
    "\n",
    "\n",
    "sample_snapshot = trajectory_forces[0].copy()\n",
    "fdm = FandeDataModule()\n",
    "atomic_groups = find_atomic_groups(sample_snapshot)\n",
    "train_centers_positions = sum(atomic_groups, []) #list(range(len(atoms)))\n",
    "train_derivatives_positions = sum(atomic_groups, [])#list(range(len(atoms)))\n",
    "fdm.atomic_groups_sample_snapshot = sample_snapshot.copy()\n",
    "fdm.atomic_groups = atomic_groups\n",
    "\n",
    "total_forces_samples_per_group = [100] * len(atomic_groups)\n",
    "high_forces_samples_per_group = [10] * len(atomic_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of traj is 5\n",
      "Total number of batches 5\n",
      "Calculating invariants on trajectory with librascal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 24.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader for group 0 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 1 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 2 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 3 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 4 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 5 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 6 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 7 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 8 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 9 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 10 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 11 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 12 created\n",
      "Number of samples in dataloader: 100\n",
      "Dataloader for group 13 created\n",
      "Number of samples in dataloader: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader_energy, dataloaders_forces = fdm.dataloaders_from_trajectory(\n",
    "                                                                trajectory_energy,\n",
    "                                                                trajectory_forces,\n",
    "                                                                # energies = None,\n",
    "                                                                # forces = None,\n",
    "                                                                atomic_groups = atomic_groups,\n",
    "                                                                centers_positions = train_centers_positions,\n",
    "                                                                derivatives_positions = train_derivatives_positions,\n",
    "                                                                energy_soap_hypers = soap_params,\n",
    "                                                                forces_soap_hypers = soap_params,\n",
    "                                                                total_forces_samples_per_group = total_forces_samples_per_group,\n",
    "                                                                high_force_samples_per_group = high_forces_samples_per_group,\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/dlbox2/anaconda3/envs/fande/lib/python3.10/sit ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelEnergy         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RawEnergyModel initialized\n",
      "Training energy model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/dlbox2/anaconda3/envs/fande/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae10063ee444e4aa758f881981d68f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Making energy model\n",
    "\n",
    "from fande.models import EnergyModel\n",
    "\n",
    "hparams = {\n",
    "        'dtype' : 'float32',\n",
    "        'device' : 'gpu',\n",
    "        'energy_model_hparams' : {\n",
    "                'num_epochs' : 100,\n",
    "                'learning_rate' : 0.01,\n",
    "        }\n",
    "        }\n",
    "       \n",
    "Energy_model = EnergyModel(\n",
    "        dataloader_energy,\n",
    "        hparams=hparams, \n",
    "        gpu_id=0)\n",
    "\n",
    "Energy_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n",
      "\n",
      "ModelForces initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 0 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae08fe4a8a994626b4835da168a0e367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 1 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7042b2ce1754357a8a711403054862e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 2 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05ff690bd914c95bf8220a36a4cf54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 3 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37eadf67e83d4de4a71a38bffe7b750b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 4 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c46f7605c6d40bf81aed4d4db8b76e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 5 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fa5881416b47f88bf7685ac02d398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 6 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9407d4819fc0445a81f35bfbe2e236a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 7 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee18658e64bf48cfb3f66251741f3e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 8 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8f56897aad46eda2e106230d0610ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 9 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bb990b9e424e679f6121b547d8a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 10 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63207288610948928af3f54d35a11758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 11 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba0adaadcb547c19b00c57dcabcec53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 12 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f2648cfda84a7b9c12d30b5148a619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name       | Type                       | Params\n",
      "----------------------------------------------------------\n",
      "0 | likelihood | GaussianLikelihood         | 1     \n",
      "1 | model      | ExactGPModelForces         | 32    \n",
      "2 | mll        | ExactMarginalLogLikelihood | 32    \n",
      "----------------------------------------------------------\n",
      "32        Trainable params\n",
      "0         Non-trainable params\n",
      "32        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training force model 13 (Total 14 models)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dec3e12d10451a8207dcbf339ae81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Fitting forces\n",
    "\n",
    "from fande.models import ModelForces, GroupModelForces\n",
    "\n",
    "\n",
    "n_steps_list = [100] * len(atomic_groups)\n",
    "lr_list = [0.1] * len(atomic_groups)\n",
    "\n",
    "models_hparams = []\n",
    "for i in range(len(atomic_groups)):\n",
    "        model_hparams = {\n",
    "        'atomic_group' : atomic_groups[i],\n",
    "        'dtype' : hparams['dtype'],\n",
    "        'device' : hparams['device'],\n",
    "        'num_epochs' : n_steps_list[i],\n",
    "        'learning_rate' : lr_list[i],\n",
    "        'soap_dim' : dataloaders_forces[i].dataset[0][0].shape[-1],\n",
    "        'soap_params' : soap_params,\n",
    "        }\n",
    "        models_hparams.append(model_hparams)\n",
    "\n",
    "\n",
    "\n",
    "hparams['per_model_hparams'] = models_hparams # access per_model_hparams by model.model_id\n",
    "gpu_id = 0\n",
    "\n",
    "\n",
    "models_forces = []\n",
    "for i in range(len(atomic_groups)):\n",
    "        model = ModelForces(\n",
    "        train_x = dataloaders_forces[i].dataset[:][0],\n",
    "        train_y = dataloaders_forces[i].dataset[:][1],\n",
    "        atomic_group = atomic_groups[i],\n",
    "        hparams = hparams,\n",
    "        id=i)\n",
    "        models_forces.append(model)\n",
    "        \n",
    "AG_force_model = GroupModelForces(\n",
    "        models= models_forces,\n",
    "        train_data_loaders = dataloaders_forces,\n",
    "        hparams=hparams, \n",
    "        gpu_id=gpu_id)\n",
    "\n",
    "AG_force_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.predict import FandePredictor\n",
    "from fande.ase import FandeCalc\n",
    "\n",
    "predictor = FandePredictor(\n",
    "        fdm,\n",
    "        AG_force_model,\n",
    "        Energy_model,\n",
    "        hparams,\n",
    "        soap_params\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[0.14562514] [0.30684346]\n"
     ]
    }
   ],
   "source": [
    "energy, energy_uncertainty = predictor.predict_energy_single_snapshot_r(traj_train[0].copy())\n",
    "print(energy, energy_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fande_calc = FandeCalc(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.15805303e-310, 1.15805303e-310, 4.65292880e-310],\n",
       "       [4.65292880e-310, 2.96439388e-323, 4.65292820e-310],\n",
       "       [1.15786563e-310, 1.15805243e-310, 1.97626258e-323],\n",
       "       ...,\n",
       "       [4.65292880e-310, 1.15776090e-310, 4.65292880e-310],\n",
       "       [1.18575755e-322, 1.15786641e-310, 8.27578358e-313],\n",
       "       [9.88131292e-324, 5.72938864e-313, 8.06358401e-313]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms = trajectory_energy[0].copy()\n",
    "\n",
    "atoms.set_calculator(fande_calc)\n",
    "\n",
    "atoms.get_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictor requires humongous amount of memory! Spare some dozens of GBs!\n"
     ]
    }
   ],
   "source": [
    "fande_calc.save_predictor(\"prrrrr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fande.models module imported...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fande.ase import FandeCalc\n",
    "\n",
    "predictor_loaded = torch.load(\"prrrrr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fande_calc_loaded = FandeCalc(predictor_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import io\n",
    "atoms = io.read(\"/data1/simulations/datasets/rotors/high_temp_ML_training_data/results_triasine_ML_2000/struct_295_295K/md_trajectory.traj\", index=\"10\")\n",
    "\n",
    "\n",
    "atoms.set_calculator(fande_calc_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomic group force model is not defined. Cannot predict forces. Returning zeros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlbox2/repos/fande/fande/data/data_module.py:435: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  X = torch.tensor(X_np_batched,dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.14562514], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms.get_potential_energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atoms.get_forces()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
